{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Differential_Learning_Rate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94d8bb3475a74d80837a23217ab83126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_613f914256b14c0fb8b4a3019f7a6243",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2035f4ac850404d91e1ca94b5602dbc",
              "IPY_MODEL_2320047b107e48ac9157a5bf19ebddd5"
            ]
          }
        },
        "613f914256b14c0fb8b4a3019f7a6243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2035f4ac850404d91e1ca94b5602dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cace031c21714fb48227f090a5fc5492",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a88b728225f497da5cb1827fcf02e30"
          }
        },
        "2320047b107e48ac9157a5bf19ebddd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa95cb1f43264cb39f64e1caea69ea80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [12:29&lt;00:00, 227514.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97a3a63129974f57a9b304d6ef467c45"
          }
        },
        "cace031c21714fb48227f090a5fc5492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a88b728225f497da5cb1827fcf02e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa95cb1f43264cb39f64e1caea69ea80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97a3a63129974f57a9b304d6ef467c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f857afc331e34327897d200aea3a2eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a97ba2a9f8c846a2ae3bf49184f416fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0d949e27f8f4991ac180994673d5d0f",
              "IPY_MODEL_3121574615b34023bd60f1e300865541"
            ]
          }
        },
        "a97ba2a9f8c846a2ae3bf49184f416fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d949e27f8f4991ac180994673d5d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28ebff4e53b148488e401d9d0b833482",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71a9bfee0ffa488e99a429171f654b7d"
          }
        },
        "3121574615b34023bd60f1e300865541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93117ada810d4ad0a6eb30049674d062",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:12&lt;00:00, 44.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f9d1dabe99d456798ad5b56b1ad2da1"
          }
        },
        "28ebff4e53b148488e401d9d0b833482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71a9bfee0ffa488e99a429171f654b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93117ada810d4ad0a6eb30049674d062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f9d1dabe99d456798ad5b56b1ad2da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravinda89/Pytorch-Tutorial/blob/main/Differential_Learning_Rate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z2kILHRWcKg"
      },
      "source": [
        "# Transfer learning - Differential Learning Rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggcpfBwQcU8"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3w2sce8WXYa"
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDchYyEo5Fe"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYMYVmxMpX2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2bec16-c45b-4073-cc62-ebcab863e974"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEw9S-Up23y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "94d8bb3475a74d80837a23217ab83126",
            "613f914256b14c0fb8b4a3019f7a6243",
            "f2035f4ac850404d91e1ca94b5602dbc",
            "2320047b107e48ac9157a5bf19ebddd5",
            "cace031c21714fb48227f090a5fc5492",
            "4a88b728225f497da5cb1827fcf02e30",
            "aa95cb1f43264cb39f64e1caea69ea80",
            "97a3a63129974f57a9b304d6ef467c45"
          ]
        },
        "outputId": "11db30eb-3c1e-43a4-e219-0dedd1db0407"
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=True, download=True,transform=transform)\n",
        "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=False, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d8bb3475a74d80837a23217ab83126",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/CIFAR10/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1CRA2mdqZ8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e37f89-68bd-438f-b875-a2cd9c554456"
      },
      "source": [
        "for images, labels in trainloader:\n",
        "  print(images.size(), labels.size())\n",
        "  break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBchPi4jvHMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259,
          "referenced_widgets": [
            "f857afc331e34327897d200aea3a2eac",
            "a97ba2a9f8c846a2ae3bf49184f416fd",
            "d0d949e27f8f4991ac180994673d5d0f",
            "3121574615b34023bd60f1e300865541",
            "28ebff4e53b148488e401d9d0b833482",
            "71a9bfee0ffa488e99a429171f654b7d",
            "93117ada810d4ad0a6eb30049674d062",
            "1f9d1dabe99d456798ad5b56b1ad2da1"
          ]
        },
        "outputId": "48f1bddf-0249-40cf-8636-b622b882298c"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f857afc331e34327897d200aea3a2eac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avx6J-_Mvfy3"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7URaKbIwhse"
      },
      "source": [
        "for i in range(0,7):\n",
        "  model.classifier[i].requires_grad = True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBWZLtJwt3P"
      },
      "source": [
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(4096,512),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.5),\n",
        "                      nn.Linear(512,10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                      )\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXPMdB3b-9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9643d3b6-9b47-4b11-80e1-d999bf46672b"
      },
      "source": [
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "      (4): LogSoftmax(dim=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IGZ_qw9NA8u"
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9-eEGnxW77"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vamBkzek_ZfR"
      },
      "source": [
        "## Training from the Fully Connected Network onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3WWNZkQ_ZfS"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeEZA-WO9joV"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ-xpFU-_ZfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "a0a7e7ba-5b75-4873-ad63-a350b9ffbc7c"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0/1 : Batch number(1/782) : Batch loss : 2.3653225898742676\n",
            "Epoch(0/1 : Batch number(2/782) : Batch loss : 2.273170232772827\n",
            "Epoch(0/1 : Batch number(3/782) : Batch loss : 2.2001216411590576\n",
            "Epoch(0/1 : Batch number(4/782) : Batch loss : 2.0917232036590576\n",
            "Epoch(0/1 : Batch number(5/782) : Batch loss : 1.9808127880096436\n",
            "Epoch(0/1 : Batch number(6/782) : Batch loss : 1.984837532043457\n",
            "Epoch(0/1 : Batch number(7/782) : Batch loss : 1.9999157190322876\n",
            "Epoch(0/1 : Batch number(8/782) : Batch loss : 1.884743094444275\n",
            "Epoch(0/1 : Batch number(9/782) : Batch loss : 1.7808301448822021\n",
            "Epoch(0/1 : Batch number(10/782) : Batch loss : 1.7544889450073242\n",
            "Epoch(0/1 : Batch number(11/782) : Batch loss : 1.6620538234710693\n",
            "Epoch(0/1 : Batch number(12/782) : Batch loss : 1.6983424425125122\n",
            "Epoch(0/1 : Batch number(13/782) : Batch loss : 1.373589038848877\n",
            "Epoch(0/1 : Batch number(14/782) : Batch loss : 1.4959750175476074\n",
            "Epoch(0/1 : Batch number(15/782) : Batch loss : 1.3911482095718384\n",
            "Epoch(0/1 : Batch number(16/782) : Batch loss : 1.517344355583191\n",
            "Epoch(0/1 : Batch number(17/782) : Batch loss : 1.4231950044631958\n",
            "Epoch(0/1 : Batch number(18/782) : Batch loss : 1.1553295850753784\n",
            "Epoch(0/1 : Batch number(19/782) : Batch loss : 1.2606210708618164\n",
            "Epoch(0/1 : Batch number(20/782) : Batch loss : 1.0615334510803223\n",
            "Epoch(0/1 : Batch number(21/782) : Batch loss : 1.087511420249939\n",
            "Epoch(0/1 : Batch number(22/782) : Batch loss : 1.1126335859298706\n",
            "Epoch(0/1 : Batch number(23/782) : Batch loss : 1.1458096504211426\n",
            "Epoch(0/1 : Batch number(24/782) : Batch loss : 1.073390007019043\n",
            "Epoch(0/1 : Batch number(25/782) : Batch loss : 1.078269362449646\n",
            "Epoch(0/1 : Batch number(26/782) : Batch loss : 0.9735251069068909\n",
            "Epoch(0/1 : Batch number(27/782) : Batch loss : 1.0414478778839111\n",
            "Epoch(0/1 : Batch number(28/782) : Batch loss : 0.9935224056243896\n",
            "Epoch(0/1 : Batch number(29/782) : Batch loss : 0.9625189304351807\n",
            "Epoch(0/1 : Batch number(30/782) : Batch loss : 0.8522980809211731\n",
            "Epoch(0/1 : Batch number(31/782) : Batch loss : 1.1234703063964844\n",
            "Epoch(0/1 : Batch number(32/782) : Batch loss : 0.8367083072662354\n",
            "Epoch(0/1 : Batch number(33/782) : Batch loss : 0.9143449068069458\n",
            "Epoch(0/1 : Batch number(34/782) : Batch loss : 1.084702491760254\n",
            "Epoch(0/1 : Batch number(35/782) : Batch loss : 0.9349896907806396\n",
            "Epoch(0/1 : Batch number(36/782) : Batch loss : 0.9923100471496582\n",
            "Epoch(0/1 : Batch number(37/782) : Batch loss : 0.9867238402366638\n",
            "Epoch(0/1 : Batch number(38/782) : Batch loss : 0.9628636837005615\n",
            "Epoch(0/1 : Batch number(39/782) : Batch loss : 0.7283376455307007\n",
            "Epoch(0/1 : Batch number(40/782) : Batch loss : 0.847449541091919\n",
            "Epoch(0/1 : Batch number(41/782) : Batch loss : 0.7745538353919983\n",
            "Epoch(0/1 : Batch number(42/782) : Batch loss : 0.8578053116798401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-78029e24b196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6j6rXQe_ZfW"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPEeLaHK_ZfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3719dc-ba26-4871-d281-19bfdeb60213"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch (1/157)\n",
            "Batch (2/157)\n",
            "Batch (3/157)\n",
            "Batch (4/157)\n",
            "Batch (5/157)\n",
            "Accuracy of the model on 320 test images: 71.875% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLAXsh1S5XB9"
      },
      "source": [
        "## Un-freezing & training on the LAST CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7nvP9B9R8b"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaUeud5I7Tez"
      },
      "source": [
        "for i in range(24,31):\n",
        "  model.features[i].requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3H1alJg-keE"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.features[24].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.features[26].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.features[28].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_-YlZp5XB-"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2dNQIjt9JQo"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ichHhboE9JQp"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbOYwAC9rVq"
      },
      "source": [
        "## Un-freezing & training on the LAST TWO CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTUgZSz9rVt"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkn85do59rVw"
      },
      "source": [
        "for i in range(17,24):\n",
        "  model.features[i].requires_grad = True"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxRZ0rJ5_SaB"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = Adam([\n",
        "    { 'params': model.features[17].parameters(), 'lr': lr/9},\n",
        "    { 'params': model.features[19].parameters(), 'lr': lr/9},\n",
        "    { 'params': model.features[21].parameters(), 'lr': lr/9},\n",
        "    { 'params': model.features[24].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.features[26].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.features[28].parameters(), 'lr': lr/3},\n",
        "    { 'params': model.classifier[0].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[3].parameters(), 'lr': lr},\n",
        "    { 'params': model.classifier[6].parameters(), 'lr': lr}\n",
        "    ], lr=lr)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrzemsJ9rV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9785d9a-b052-470c-e2d2-c5252567aefa"
      },
      "source": [
        "model = model.to(device)\n",
        "#optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0/1 : Batch number(1/782) : Batch loss : 0.6579272150993347\n",
            "Epoch(0/1 : Batch number(2/782) : Batch loss : 0.7019481658935547\n",
            "Epoch(0/1 : Batch number(3/782) : Batch loss : 0.9410093426704407\n",
            "Epoch(0/1 : Batch number(4/782) : Batch loss : 0.7407578825950623\n",
            "Epoch(0/1 : Batch number(5/782) : Batch loss : 0.770391583442688\n",
            "Epoch(0/1 : Batch number(6/782) : Batch loss : 0.909604549407959\n",
            "Epoch(0/1 : Batch number(7/782) : Batch loss : 0.5332302451133728\n",
            "Epoch(0/1 : Batch number(8/782) : Batch loss : 0.6948360800743103\n",
            "Epoch(0/1 : Batch number(9/782) : Batch loss : 0.5841999053955078\n",
            "Epoch(0/1 : Batch number(10/782) : Batch loss : 0.7174786329269409\n",
            "Epoch(0/1 : Batch number(11/782) : Batch loss : 0.8692085146903992\n",
            "Epoch(0/1 : Batch number(12/782) : Batch loss : 0.8495988249778748\n",
            "Epoch(0/1 : Batch number(13/782) : Batch loss : 0.7417474985122681\n",
            "Epoch(0/1 : Batch number(14/782) : Batch loss : 0.745541512966156\n",
            "Epoch(0/1 : Batch number(15/782) : Batch loss : 0.6796875596046448\n",
            "Epoch(0/1 : Batch number(16/782) : Batch loss : 0.6414957642555237\n",
            "Epoch(0/1 : Batch number(17/782) : Batch loss : 0.6497596502304077\n",
            "Epoch(0/1 : Batch number(18/782) : Batch loss : 0.7520260810852051\n",
            "Epoch(0/1 : Batch number(19/782) : Batch loss : 0.7153664827346802\n",
            "Epoch(0/1 : Batch number(20/782) : Batch loss : 0.5443366169929504\n",
            "Epoch(0/1 : Batch number(21/782) : Batch loss : 0.5267357230186462\n",
            "Epoch(0/1 : Batch number(22/782) : Batch loss : 0.5945096015930176\n",
            "Epoch(0/1 : Batch number(23/782) : Batch loss : 0.5554105043411255\n",
            "Epoch(0/1 : Batch number(24/782) : Batch loss : 0.5901615023612976\n",
            "Epoch(0/1 : Batch number(25/782) : Batch loss : 0.7218323945999146\n",
            "Epoch(0/1 : Batch number(26/782) : Batch loss : 0.8618009090423584\n",
            "Epoch(0/1 : Batch number(27/782) : Batch loss : 0.5892362594604492\n",
            "Epoch(0/1 : Batch number(28/782) : Batch loss : 0.8459992408752441\n",
            "Epoch(0/1 : Batch number(29/782) : Batch loss : 0.6358364224433899\n",
            "Epoch(0/1 : Batch number(30/782) : Batch loss : 0.5550313591957092\n",
            "Epoch(0/1 : Batch number(31/782) : Batch loss : 0.5638298392295837\n",
            "Epoch(0/1 : Batch number(32/782) : Batch loss : 0.7620012164115906\n",
            "Epoch(0/1 : Batch number(33/782) : Batch loss : 0.4534878432750702\n",
            "Epoch(0/1 : Batch number(34/782) : Batch loss : 0.6917520761489868\n",
            "Epoch(0/1 : Batch number(35/782) : Batch loss : 0.5973862409591675\n",
            "Epoch(0/1 : Batch number(36/782) : Batch loss : 0.6397346258163452\n",
            "Epoch(0/1 : Batch number(37/782) : Batch loss : 0.7767850160598755\n",
            "Epoch(0/1 : Batch number(38/782) : Batch loss : 0.6196934580802917\n",
            "Epoch(0/1 : Batch number(39/782) : Batch loss : 0.6650182604789734\n",
            "Epoch(0/1 : Batch number(40/782) : Batch loss : 0.4863780438899994\n",
            "Epoch(0/1 : Batch number(41/782) : Batch loss : 0.5808830261230469\n",
            "Epoch(0/1 : Batch number(42/782) : Batch loss : 0.4531756639480591\n",
            "Epoch(0/1 : Batch number(43/782) : Batch loss : 0.5325746536254883\n",
            "Epoch(0/1 : Batch number(44/782) : Batch loss : 0.6157854795455933\n",
            "Epoch(0/1 : Batch number(45/782) : Batch loss : 0.6255385875701904\n",
            "Epoch(0/1 : Batch number(46/782) : Batch loss : 0.6240941882133484\n",
            "Epoch(0/1 : Batch number(47/782) : Batch loss : 0.651552140712738\n",
            "Epoch(0/1 : Batch number(48/782) : Batch loss : 0.776741087436676\n",
            "Epoch(0/1 : Batch number(49/782) : Batch loss : 0.6028205156326294\n",
            "Epoch(0/1 : Batch number(50/782) : Batch loss : 0.7673656940460205\n",
            "Epoch(0/1 : Batch number(51/782) : Batch loss : 0.7215231657028198\n",
            "Epoch(0/1 : Batch number(52/782) : Batch loss : 0.6120693683624268\n",
            "Epoch(0/1 : Batch number(53/782) : Batch loss : 0.6557570099830627\n",
            "Epoch(0/1 : Batch number(54/782) : Batch loss : 0.5229906439781189\n",
            "Epoch(0/1 : Batch number(55/782) : Batch loss : 0.6141656041145325\n",
            "Epoch(0/1 : Batch number(56/782) : Batch loss : 0.48179545998573303\n",
            "Epoch(0/1 : Batch number(57/782) : Batch loss : 0.5509583950042725\n",
            "Epoch(0/1 : Batch number(58/782) : Batch loss : 0.6265583634376526\n",
            "Epoch(0/1 : Batch number(59/782) : Batch loss : 0.5311775803565979\n",
            "Epoch(0/1 : Batch number(60/782) : Batch loss : 0.36555853486061096\n",
            "Epoch(0/1 : Batch number(61/782) : Batch loss : 0.4391925632953644\n",
            "Epoch(0/1 : Batch number(62/782) : Batch loss : 0.5926873683929443\n",
            "Epoch(0/1 : Batch number(63/782) : Batch loss : 0.5600179433822632\n",
            "Epoch(0/1 : Batch number(64/782) : Batch loss : 0.5913797616958618\n",
            "Epoch(0/1 : Batch number(65/782) : Batch loss : 0.6630039811134338\n",
            "Epoch(0/1 : Batch number(66/782) : Batch loss : 0.45123010873794556\n",
            "Epoch(0/1 : Batch number(67/782) : Batch loss : 0.8204618096351624\n",
            "Epoch(0/1 : Batch number(68/782) : Batch loss : 0.4684631824493408\n",
            "Epoch(0/1 : Batch number(69/782) : Batch loss : 0.712620735168457\n",
            "Epoch(0/1 : Batch number(70/782) : Batch loss : 0.6485069990158081\n",
            "Epoch(0/1 : Batch number(71/782) : Batch loss : 0.5933734774589539\n",
            "Epoch(0/1 : Batch number(72/782) : Batch loss : 0.5376734137535095\n",
            "Epoch(0/1 : Batch number(73/782) : Batch loss : 0.4112900197505951\n",
            "Epoch(0/1 : Batch number(74/782) : Batch loss : 0.6572253108024597\n",
            "Epoch(0/1 : Batch number(75/782) : Batch loss : 0.4139103591442108\n",
            "Epoch(0/1 : Batch number(76/782) : Batch loss : 0.5008101463317871\n",
            "Epoch(0/1 : Batch number(77/782) : Batch loss : 0.5857987999916077\n",
            "Epoch(0/1 : Batch number(78/782) : Batch loss : 0.45461028814315796\n",
            "Epoch(0/1 : Batch number(79/782) : Batch loss : 0.6121941804885864\n",
            "Epoch(0/1 : Batch number(80/782) : Batch loss : 0.3752099871635437\n",
            "Epoch(0/1 : Batch number(81/782) : Batch loss : 0.6473802924156189\n",
            "Epoch(0/1 : Batch number(82/782) : Batch loss : 0.4172394871711731\n",
            "Epoch(0/1 : Batch number(83/782) : Batch loss : 0.6758303046226501\n",
            "Epoch(0/1 : Batch number(84/782) : Batch loss : 0.5470591187477112\n",
            "Epoch(0/1 : Batch number(85/782) : Batch loss : 0.5533645749092102\n",
            "Epoch(0/1 : Batch number(86/782) : Batch loss : 0.4267815947532654\n",
            "Epoch(0/1 : Batch number(87/782) : Batch loss : 0.49105575680732727\n",
            "Epoch(0/1 : Batch number(88/782) : Batch loss : 0.5087127089500427\n",
            "Epoch(0/1 : Batch number(89/782) : Batch loss : 0.44289013743400574\n",
            "Epoch(0/1 : Batch number(90/782) : Batch loss : 0.4060920774936676\n",
            "Epoch(0/1 : Batch number(91/782) : Batch loss : 0.47142550349235535\n",
            "Epoch(0/1 : Batch number(92/782) : Batch loss : 0.495980829000473\n",
            "Epoch(0/1 : Batch number(93/782) : Batch loss : 0.4989534914493561\n",
            "Epoch(0/1 : Batch number(94/782) : Batch loss : 0.5206977128982544\n",
            "Epoch(0/1 : Batch number(95/782) : Batch loss : 0.5402290225028992\n",
            "Epoch(0/1 : Batch number(96/782) : Batch loss : 0.617725133895874\n",
            "Epoch(0/1 : Batch number(97/782) : Batch loss : 0.6030407547950745\n",
            "Epoch(0/1 : Batch number(98/782) : Batch loss : 0.6647365689277649\n",
            "Epoch(0/1 : Batch number(99/782) : Batch loss : 0.6796330213546753\n",
            "Epoch(0/1 : Batch number(100/782) : Batch loss : 0.47272104024887085\n",
            "Epoch(0/1 : Batch number(101/782) : Batch loss : 0.4953356385231018\n",
            "Epoch(0/1 : Batch number(102/782) : Batch loss : 0.4167758524417877\n",
            "Epoch(0/1 : Batch number(103/782) : Batch loss : 0.5039534568786621\n",
            "Epoch(0/1 : Batch number(104/782) : Batch loss : 0.4880547523498535\n",
            "Epoch(0/1 : Batch number(105/782) : Batch loss : 0.545539379119873\n",
            "Epoch(0/1 : Batch number(106/782) : Batch loss : 0.6093889474868774\n",
            "Epoch(0/1 : Batch number(107/782) : Batch loss : 0.5334317088127136\n",
            "Epoch(0/1 : Batch number(108/782) : Batch loss : 0.6212425231933594\n",
            "Epoch(0/1 : Batch number(109/782) : Batch loss : 0.647396445274353\n",
            "Epoch(0/1 : Batch number(110/782) : Batch loss : 0.4521688222885132\n",
            "Epoch(0/1 : Batch number(111/782) : Batch loss : 0.591649055480957\n",
            "Epoch(0/1 : Batch number(112/782) : Batch loss : 0.41724321246147156\n",
            "Epoch(0/1 : Batch number(113/782) : Batch loss : 0.3274881839752197\n",
            "Epoch(0/1 : Batch number(114/782) : Batch loss : 0.6742817759513855\n",
            "Epoch(0/1 : Batch number(115/782) : Batch loss : 0.5910883545875549\n",
            "Epoch(0/1 : Batch number(116/782) : Batch loss : 0.46785563230514526\n",
            "Epoch(0/1 : Batch number(117/782) : Batch loss : 0.4780123829841614\n",
            "Epoch(0/1 : Batch number(118/782) : Batch loss : 0.41204917430877686\n",
            "Epoch(0/1 : Batch number(119/782) : Batch loss : 0.3647783398628235\n",
            "Epoch(0/1 : Batch number(120/782) : Batch loss : 0.5392484068870544\n",
            "Epoch(0/1 : Batch number(121/782) : Batch loss : 0.629125714302063\n",
            "Epoch(0/1 : Batch number(122/782) : Batch loss : 0.47321444749832153\n",
            "Epoch(0/1 : Batch number(123/782) : Batch loss : 0.7004424333572388\n",
            "Epoch(0/1 : Batch number(124/782) : Batch loss : 0.34851011633872986\n",
            "Epoch(0/1 : Batch number(125/782) : Batch loss : 0.5271886587142944\n",
            "Epoch(0/1 : Batch number(126/782) : Batch loss : 0.40734246373176575\n",
            "Epoch(0/1 : Batch number(127/782) : Batch loss : 0.5932446718215942\n",
            "Epoch(0/1 : Batch number(128/782) : Batch loss : 0.6972134709358215\n",
            "Epoch(0/1 : Batch number(129/782) : Batch loss : 0.5549393892288208\n",
            "Epoch(0/1 : Batch number(130/782) : Batch loss : 0.505685567855835\n",
            "Epoch(0/1 : Batch number(131/782) : Batch loss : 0.5332347750663757\n",
            "Epoch(0/1 : Batch number(132/782) : Batch loss : 0.5437647700309753\n",
            "Epoch(0/1 : Batch number(133/782) : Batch loss : 0.4517357349395752\n",
            "Epoch(0/1 : Batch number(134/782) : Batch loss : 0.737482488155365\n",
            "Epoch(0/1 : Batch number(135/782) : Batch loss : 0.6560799479484558\n",
            "Epoch(0/1 : Batch number(136/782) : Batch loss : 0.611893355846405\n",
            "Epoch(0/1 : Batch number(137/782) : Batch loss : 0.6702911257743835\n",
            "Epoch(0/1 : Batch number(138/782) : Batch loss : 0.5552342534065247\n",
            "Epoch(0/1 : Batch number(139/782) : Batch loss : 0.5301598310470581\n",
            "Epoch(0/1 : Batch number(140/782) : Batch loss : 0.5712043642997742\n",
            "Epoch(0/1 : Batch number(141/782) : Batch loss : 0.4759552776813507\n",
            "Epoch(0/1 : Batch number(142/782) : Batch loss : 0.5463603138923645\n",
            "Epoch(0/1 : Batch number(143/782) : Batch loss : 0.49824070930480957\n",
            "Epoch(0/1 : Batch number(144/782) : Batch loss : 0.44427016377449036\n",
            "Epoch(0/1 : Batch number(145/782) : Batch loss : 0.4744601547718048\n",
            "Epoch(0/1 : Batch number(146/782) : Batch loss : 0.6152166128158569\n",
            "Epoch(0/1 : Batch number(147/782) : Batch loss : 0.5154752731323242\n",
            "Epoch(0/1 : Batch number(148/782) : Batch loss : 0.5406957864761353\n",
            "Epoch(0/1 : Batch number(149/782) : Batch loss : 0.6927167177200317\n",
            "Epoch(0/1 : Batch number(150/782) : Batch loss : 0.4908936023712158\n",
            "Epoch(0/1 : Batch number(151/782) : Batch loss : 0.5696372985839844\n",
            "Epoch(0/1 : Batch number(152/782) : Batch loss : 0.3882920742034912\n",
            "Epoch(0/1 : Batch number(153/782) : Batch loss : 0.6048420071601868\n",
            "Epoch(0/1 : Batch number(154/782) : Batch loss : 0.5281757116317749\n",
            "Epoch(0/1 : Batch number(155/782) : Batch loss : 0.629687488079071\n",
            "Epoch(0/1 : Batch number(156/782) : Batch loss : 0.3717743158340454\n",
            "Epoch(0/1 : Batch number(157/782) : Batch loss : 0.5123059153556824\n",
            "Epoch(0/1 : Batch number(158/782) : Batch loss : 0.5578536987304688\n",
            "Epoch(0/1 : Batch number(159/782) : Batch loss : 0.45029717683792114\n",
            "Epoch(0/1 : Batch number(160/782) : Batch loss : 0.4974071979522705\n",
            "Epoch(0/1 : Batch number(161/782) : Batch loss : 0.558590292930603\n",
            "Epoch(0/1 : Batch number(162/782) : Batch loss : 0.611290693283081\n",
            "Epoch(0/1 : Batch number(163/782) : Batch loss : 0.6041539907455444\n",
            "Epoch(0/1 : Batch number(164/782) : Batch loss : 0.4825130105018616\n",
            "Epoch(0/1 : Batch number(165/782) : Batch loss : 0.4668032228946686\n",
            "Epoch(0/1 : Batch number(166/782) : Batch loss : 0.4513246417045593\n",
            "Epoch(0/1 : Batch number(167/782) : Batch loss : 0.4315546452999115\n",
            "Epoch(0/1 : Batch number(168/782) : Batch loss : 0.42374473810195923\n",
            "Epoch(0/1 : Batch number(169/782) : Batch loss : 0.4757130444049835\n",
            "Epoch(0/1 : Batch number(170/782) : Batch loss : 0.6010188460350037\n",
            "Epoch(0/1 : Batch number(171/782) : Batch loss : 0.5600057244300842\n",
            "Epoch(0/1 : Batch number(172/782) : Batch loss : 0.5785913467407227\n",
            "Epoch(0/1 : Batch number(173/782) : Batch loss : 0.4658288359642029\n",
            "Epoch(0/1 : Batch number(174/782) : Batch loss : 0.4669204354286194\n",
            "Epoch(0/1 : Batch number(175/782) : Batch loss : 0.5010499358177185\n",
            "Epoch(0/1 : Batch number(176/782) : Batch loss : 0.45143136382102966\n",
            "Epoch(0/1 : Batch number(177/782) : Batch loss : 0.6148678660392761\n",
            "Epoch(0/1 : Batch number(178/782) : Batch loss : 0.3934086263179779\n",
            "Epoch(0/1 : Batch number(179/782) : Batch loss : 0.46920740604400635\n",
            "Epoch(0/1 : Batch number(180/782) : Batch loss : 0.647148847579956\n",
            "Epoch(0/1 : Batch number(181/782) : Batch loss : 0.5473220348358154\n",
            "Epoch(0/1 : Batch number(182/782) : Batch loss : 0.3952028751373291\n",
            "Epoch(0/1 : Batch number(183/782) : Batch loss : 0.5254465341567993\n",
            "Epoch(0/1 : Batch number(184/782) : Batch loss : 0.749369204044342\n",
            "Epoch(0/1 : Batch number(185/782) : Batch loss : 0.4827970564365387\n",
            "Epoch(0/1 : Batch number(186/782) : Batch loss : 0.5548226237297058\n",
            "Epoch(0/1 : Batch number(187/782) : Batch loss : 0.5746497511863708\n",
            "Epoch(0/1 : Batch number(188/782) : Batch loss : 0.8647653460502625\n",
            "Epoch(0/1 : Batch number(189/782) : Batch loss : 0.6014209389686584\n",
            "Epoch(0/1 : Batch number(190/782) : Batch loss : 0.3650214672088623\n",
            "Epoch(0/1 : Batch number(191/782) : Batch loss : 0.4290526509284973\n",
            "Epoch(0/1 : Batch number(192/782) : Batch loss : 0.4265565574169159\n",
            "Epoch(0/1 : Batch number(193/782) : Batch loss : 0.5763117074966431\n",
            "Epoch(0/1 : Batch number(194/782) : Batch loss : 0.32584893703460693\n",
            "Epoch(0/1 : Batch number(195/782) : Batch loss : 0.3367931842803955\n",
            "Epoch(0/1 : Batch number(196/782) : Batch loss : 0.580297589302063\n",
            "Epoch(0/1 : Batch number(197/782) : Batch loss : 0.6462653279304504\n",
            "Epoch(0/1 : Batch number(198/782) : Batch loss : 0.42699775099754333\n",
            "Epoch(0/1 : Batch number(199/782) : Batch loss : 0.4393896460533142\n",
            "Epoch(0/1 : Batch number(200/782) : Batch loss : 0.31259170174598694\n",
            "Epoch(0/1 : Batch number(201/782) : Batch loss : 0.5420820713043213\n",
            "Epoch(0/1 : Batch number(202/782) : Batch loss : 0.40149667859077454\n",
            "Epoch(0/1 : Batch number(203/782) : Batch loss : 0.39030539989471436\n",
            "Epoch(0/1 : Batch number(204/782) : Batch loss : 0.49644002318382263\n",
            "Epoch(0/1 : Batch number(205/782) : Batch loss : 0.3324686586856842\n",
            "Epoch(0/1 : Batch number(206/782) : Batch loss : 0.6722936034202576\n",
            "Epoch(0/1 : Batch number(207/782) : Batch loss : 0.6099380850791931\n",
            "Epoch(0/1 : Batch number(208/782) : Batch loss : 0.5057274103164673\n",
            "Epoch(0/1 : Batch number(209/782) : Batch loss : 0.4170997440814972\n",
            "Epoch(0/1 : Batch number(210/782) : Batch loss : 0.6679758429527283\n",
            "Epoch(0/1 : Batch number(211/782) : Batch loss : 0.5670361518859863\n",
            "Epoch(0/1 : Batch number(212/782) : Batch loss : 0.7090365290641785\n",
            "Epoch(0/1 : Batch number(213/782) : Batch loss : 0.4211905002593994\n",
            "Epoch(0/1 : Batch number(214/782) : Batch loss : 0.6303078532218933\n",
            "Epoch(0/1 : Batch number(215/782) : Batch loss : 0.503913402557373\n",
            "Epoch(0/1 : Batch number(216/782) : Batch loss : 0.31110844016075134\n",
            "Epoch(0/1 : Batch number(217/782) : Batch loss : 0.6764963269233704\n",
            "Epoch(0/1 : Batch number(218/782) : Batch loss : 0.5060624480247498\n",
            "Epoch(0/1 : Batch number(219/782) : Batch loss : 0.5936644673347473\n",
            "Epoch(0/1 : Batch number(220/782) : Batch loss : 0.37367621064186096\n",
            "Epoch(0/1 : Batch number(221/782) : Batch loss : 0.6218054294586182\n",
            "Epoch(0/1 : Batch number(222/782) : Batch loss : 0.5769273638725281\n",
            "Epoch(0/1 : Batch number(223/782) : Batch loss : 0.5322239995002747\n",
            "Epoch(0/1 : Batch number(224/782) : Batch loss : 0.40812191367149353\n",
            "Epoch(0/1 : Batch number(225/782) : Batch loss : 0.6432998180389404\n",
            "Epoch(0/1 : Batch number(226/782) : Batch loss : 0.6532902717590332\n",
            "Epoch(0/1 : Batch number(227/782) : Batch loss : 0.6311318874359131\n",
            "Epoch(0/1 : Batch number(228/782) : Batch loss : 0.5064088106155396\n",
            "Epoch(0/1 : Batch number(229/782) : Batch loss : 0.5402284264564514\n",
            "Epoch(0/1 : Batch number(230/782) : Batch loss : 0.7278536558151245\n",
            "Epoch(0/1 : Batch number(231/782) : Batch loss : 0.41060543060302734\n",
            "Epoch(0/1 : Batch number(232/782) : Batch loss : 0.3900260627269745\n",
            "Epoch(0/1 : Batch number(233/782) : Batch loss : 0.4875422418117523\n",
            "Epoch(0/1 : Batch number(234/782) : Batch loss : 0.4155122637748718\n",
            "Epoch(0/1 : Batch number(235/782) : Batch loss : 0.42465487122535706\n",
            "Epoch(0/1 : Batch number(236/782) : Batch loss : 0.37501227855682373\n",
            "Epoch(0/1 : Batch number(237/782) : Batch loss : 0.34534716606140137\n",
            "Epoch(0/1 : Batch number(238/782) : Batch loss : 0.552980899810791\n",
            "Epoch(0/1 : Batch number(239/782) : Batch loss : 0.2794496417045593\n",
            "Epoch(0/1 : Batch number(240/782) : Batch loss : 0.4609602391719818\n",
            "Epoch(0/1 : Batch number(241/782) : Batch loss : 0.3288364112377167\n",
            "Epoch(0/1 : Batch number(242/782) : Batch loss : 0.5330399870872498\n",
            "Epoch(0/1 : Batch number(243/782) : Batch loss : 0.5325630307197571\n",
            "Epoch(0/1 : Batch number(244/782) : Batch loss : 0.46693792939186096\n",
            "Epoch(0/1 : Batch number(245/782) : Batch loss : 0.6074686050415039\n",
            "Epoch(0/1 : Batch number(246/782) : Batch loss : 0.6967816352844238\n",
            "Epoch(0/1 : Batch number(247/782) : Batch loss : 0.42996945977211\n",
            "Epoch(0/1 : Batch number(248/782) : Batch loss : 0.6176620125770569\n",
            "Epoch(0/1 : Batch number(249/782) : Batch loss : 0.47215163707733154\n",
            "Epoch(0/1 : Batch number(250/782) : Batch loss : 0.614274263381958\n",
            "Epoch(0/1 : Batch number(251/782) : Batch loss : 0.34934917092323303\n",
            "Epoch(0/1 : Batch number(252/782) : Batch loss : 0.4743632972240448\n",
            "Epoch(0/1 : Batch number(253/782) : Batch loss : 0.5236738920211792\n",
            "Epoch(0/1 : Batch number(254/782) : Batch loss : 0.6264523267745972\n",
            "Epoch(0/1 : Batch number(255/782) : Batch loss : 0.4844229519367218\n",
            "Epoch(0/1 : Batch number(256/782) : Batch loss : 0.4043652415275574\n",
            "Epoch(0/1 : Batch number(257/782) : Batch loss : 0.3941381275653839\n",
            "Epoch(0/1 : Batch number(258/782) : Batch loss : 0.4452531635761261\n",
            "Epoch(0/1 : Batch number(259/782) : Batch loss : 0.6239647269248962\n",
            "Epoch(0/1 : Batch number(260/782) : Batch loss : 0.5387266278266907\n",
            "Epoch(0/1 : Batch number(261/782) : Batch loss : 0.6147404909133911\n",
            "Epoch(0/1 : Batch number(262/782) : Batch loss : 0.48635348677635193\n",
            "Epoch(0/1 : Batch number(263/782) : Batch loss : 0.45929446816444397\n",
            "Epoch(0/1 : Batch number(264/782) : Batch loss : 0.6056225299835205\n",
            "Epoch(0/1 : Batch number(265/782) : Batch loss : 0.5364182591438293\n",
            "Epoch(0/1 : Batch number(266/782) : Batch loss : 0.4367441236972809\n",
            "Epoch(0/1 : Batch number(267/782) : Batch loss : 0.41012755036354065\n",
            "Epoch(0/1 : Batch number(268/782) : Batch loss : 0.38923346996307373\n",
            "Epoch(0/1 : Batch number(269/782) : Batch loss : 0.4130883812904358\n",
            "Epoch(0/1 : Batch number(270/782) : Batch loss : 0.44453907012939453\n",
            "Epoch(0/1 : Batch number(271/782) : Batch loss : 0.42321979999542236\n",
            "Epoch(0/1 : Batch number(272/782) : Batch loss : 0.5435386896133423\n",
            "Epoch(0/1 : Batch number(273/782) : Batch loss : 0.46548742055892944\n",
            "Epoch(0/1 : Batch number(274/782) : Batch loss : 0.6538677215576172\n",
            "Epoch(0/1 : Batch number(275/782) : Batch loss : 0.586722731590271\n",
            "Epoch(0/1 : Batch number(276/782) : Batch loss : 0.6371403336524963\n",
            "Epoch(0/1 : Batch number(277/782) : Batch loss : 0.4667245149612427\n",
            "Epoch(0/1 : Batch number(278/782) : Batch loss : 0.6265382766723633\n",
            "Epoch(0/1 : Batch number(279/782) : Batch loss : 0.6327082514762878\n",
            "Epoch(0/1 : Batch number(280/782) : Batch loss : 0.5006461143493652\n",
            "Epoch(0/1 : Batch number(281/782) : Batch loss : 0.4377025365829468\n",
            "Epoch(0/1 : Batch number(282/782) : Batch loss : 0.520835280418396\n",
            "Epoch(0/1 : Batch number(283/782) : Batch loss : 0.34618809819221497\n",
            "Epoch(0/1 : Batch number(284/782) : Batch loss : 0.5322540998458862\n",
            "Epoch(0/1 : Batch number(285/782) : Batch loss : 0.4596558213233948\n",
            "Epoch(0/1 : Batch number(286/782) : Batch loss : 0.6964553594589233\n",
            "Epoch(0/1 : Batch number(287/782) : Batch loss : 0.5888358354568481\n",
            "Epoch(0/1 : Batch number(288/782) : Batch loss : 0.36065474152565\n",
            "Epoch(0/1 : Batch number(289/782) : Batch loss : 0.5907790660858154\n",
            "Epoch(0/1 : Batch number(290/782) : Batch loss : 0.3074648678302765\n",
            "Epoch(0/1 : Batch number(291/782) : Batch loss : 0.4880673587322235\n",
            "Epoch(0/1 : Batch number(292/782) : Batch loss : 0.43448111414909363\n",
            "Epoch(0/1 : Batch number(293/782) : Batch loss : 0.45880451798439026\n",
            "Epoch(0/1 : Batch number(294/782) : Batch loss : 0.5438753962516785\n",
            "Epoch(0/1 : Batch number(295/782) : Batch loss : 0.48213884234428406\n",
            "Epoch(0/1 : Batch number(296/782) : Batch loss : 0.43652236461639404\n",
            "Epoch(0/1 : Batch number(297/782) : Batch loss : 0.40501344203948975\n",
            "Epoch(0/1 : Batch number(298/782) : Batch loss : 0.4841722249984741\n",
            "Epoch(0/1 : Batch number(299/782) : Batch loss : 0.7651511430740356\n",
            "Epoch(0/1 : Batch number(300/782) : Batch loss : 0.6107858419418335\n",
            "Epoch(0/1 : Batch number(301/782) : Batch loss : 0.45903417468070984\n",
            "Epoch(0/1 : Batch number(302/782) : Batch loss : 0.5432748198509216\n",
            "Epoch(0/1 : Batch number(303/782) : Batch loss : 0.7283677458763123\n",
            "Epoch(0/1 : Batch number(304/782) : Batch loss : 0.5441992282867432\n",
            "Epoch(0/1 : Batch number(305/782) : Batch loss : 0.4294905960559845\n",
            "Epoch(0/1 : Batch number(306/782) : Batch loss : 0.6197350025177002\n",
            "Epoch(0/1 : Batch number(307/782) : Batch loss : 0.49419963359832764\n",
            "Epoch(0/1 : Batch number(308/782) : Batch loss : 0.4387653172016144\n",
            "Epoch(0/1 : Batch number(309/782) : Batch loss : 0.29639938473701477\n",
            "Epoch(0/1 : Batch number(310/782) : Batch loss : 0.57058185338974\n",
            "Epoch(0/1 : Batch number(311/782) : Batch loss : 0.38055846095085144\n",
            "Epoch(0/1 : Batch number(312/782) : Batch loss : 0.5285714864730835\n",
            "Epoch(0/1 : Batch number(313/782) : Batch loss : 0.47238051891326904\n",
            "Epoch(0/1 : Batch number(314/782) : Batch loss : 0.5784378051757812\n",
            "Epoch(0/1 : Batch number(315/782) : Batch loss : 0.30357423424720764\n",
            "Epoch(0/1 : Batch number(316/782) : Batch loss : 0.43272387981414795\n",
            "Epoch(0/1 : Batch number(317/782) : Batch loss : 0.47549811005592346\n",
            "Epoch(0/1 : Batch number(318/782) : Batch loss : 0.6936466097831726\n",
            "Epoch(0/1 : Batch number(319/782) : Batch loss : 0.3948173224925995\n",
            "Epoch(0/1 : Batch number(320/782) : Batch loss : 0.2835389971733093\n",
            "Epoch(0/1 : Batch number(321/782) : Batch loss : 0.5671955943107605\n",
            "Epoch(0/1 : Batch number(322/782) : Batch loss : 0.40740469098091125\n",
            "Epoch(0/1 : Batch number(323/782) : Batch loss : 0.6058034896850586\n",
            "Epoch(0/1 : Batch number(324/782) : Batch loss : 0.4446134567260742\n",
            "Epoch(0/1 : Batch number(325/782) : Batch loss : 0.4662068784236908\n",
            "Epoch(0/1 : Batch number(326/782) : Batch loss : 0.3848646581172943\n",
            "Epoch(0/1 : Batch number(327/782) : Batch loss : 0.49581748247146606\n",
            "Epoch(0/1 : Batch number(328/782) : Batch loss : 0.44741013646125793\n",
            "Epoch(0/1 : Batch number(329/782) : Batch loss : 0.44199779629707336\n",
            "Epoch(0/1 : Batch number(330/782) : Batch loss : 0.33015769720077515\n",
            "Epoch(0/1 : Batch number(331/782) : Batch loss : 0.6148641109466553\n",
            "Epoch(0/1 : Batch number(332/782) : Batch loss : 0.3156128525733948\n",
            "Epoch(0/1 : Batch number(333/782) : Batch loss : 0.4419882595539093\n",
            "Epoch(0/1 : Batch number(334/782) : Batch loss : 0.5164100527763367\n",
            "Epoch(0/1 : Batch number(335/782) : Batch loss : 0.34704118967056274\n",
            "Epoch(0/1 : Batch number(336/782) : Batch loss : 0.3348252475261688\n",
            "Epoch(0/1 : Batch number(337/782) : Batch loss : 0.18635985255241394\n",
            "Epoch(0/1 : Batch number(338/782) : Batch loss : 0.45451387763023376\n",
            "Epoch(0/1 : Batch number(339/782) : Batch loss : 0.5655921697616577\n",
            "Epoch(0/1 : Batch number(340/782) : Batch loss : 0.5719902515411377\n",
            "Epoch(0/1 : Batch number(341/782) : Batch loss : 0.459171861410141\n",
            "Epoch(0/1 : Batch number(342/782) : Batch loss : 0.6487954258918762\n",
            "Epoch(0/1 : Batch number(343/782) : Batch loss : 0.6129071712493896\n",
            "Epoch(0/1 : Batch number(344/782) : Batch loss : 0.37828317284584045\n",
            "Epoch(0/1 : Batch number(345/782) : Batch loss : 0.5819293856620789\n",
            "Epoch(0/1 : Batch number(346/782) : Batch loss : 0.5966216325759888\n",
            "Epoch(0/1 : Batch number(347/782) : Batch loss : 0.4510134756565094\n",
            "Epoch(0/1 : Batch number(348/782) : Batch loss : 0.28613078594207764\n",
            "Epoch(0/1 : Batch number(349/782) : Batch loss : 0.4680324196815491\n",
            "Epoch(0/1 : Batch number(350/782) : Batch loss : 0.5578868389129639\n",
            "Epoch(0/1 : Batch number(351/782) : Batch loss : 0.5303688645362854\n",
            "Epoch(0/1 : Batch number(352/782) : Batch loss : 0.4641125202178955\n",
            "Epoch(0/1 : Batch number(353/782) : Batch loss : 0.35239335894584656\n",
            "Epoch(0/1 : Batch number(354/782) : Batch loss : 0.4267558455467224\n",
            "Epoch(0/1 : Batch number(355/782) : Batch loss : 0.5292744636535645\n",
            "Epoch(0/1 : Batch number(356/782) : Batch loss : 0.4210182726383209\n",
            "Epoch(0/1 : Batch number(357/782) : Batch loss : 0.44525110721588135\n",
            "Epoch(0/1 : Batch number(358/782) : Batch loss : 0.3999815285205841\n",
            "Epoch(0/1 : Batch number(359/782) : Batch loss : 0.44967758655548096\n",
            "Epoch(0/1 : Batch number(360/782) : Batch loss : 0.3157065212726593\n",
            "Epoch(0/1 : Batch number(361/782) : Batch loss : 0.33457669615745544\n",
            "Epoch(0/1 : Batch number(362/782) : Batch loss : 0.40161630511283875\n",
            "Epoch(0/1 : Batch number(363/782) : Batch loss : 0.2849719524383545\n",
            "Epoch(0/1 : Batch number(364/782) : Batch loss : 0.48146870732307434\n",
            "Epoch(0/1 : Batch number(365/782) : Batch loss : 0.3587881922721863\n",
            "Epoch(0/1 : Batch number(366/782) : Batch loss : 0.3031631112098694\n",
            "Epoch(0/1 : Batch number(367/782) : Batch loss : 0.4694972634315491\n",
            "Epoch(0/1 : Batch number(368/782) : Batch loss : 0.6957656741142273\n",
            "Epoch(0/1 : Batch number(369/782) : Batch loss : 0.40613436698913574\n",
            "Epoch(0/1 : Batch number(370/782) : Batch loss : 0.5203195214271545\n",
            "Epoch(0/1 : Batch number(371/782) : Batch loss : 0.4370275139808655\n",
            "Epoch(0/1 : Batch number(372/782) : Batch loss : 0.3254941701889038\n",
            "Epoch(0/1 : Batch number(373/782) : Batch loss : 0.823083221912384\n",
            "Epoch(0/1 : Batch number(374/782) : Batch loss : 0.383073091506958\n",
            "Epoch(0/1 : Batch number(375/782) : Batch loss : 0.2729376554489136\n",
            "Epoch(0/1 : Batch number(376/782) : Batch loss : 0.31609129905700684\n",
            "Epoch(0/1 : Batch number(377/782) : Batch loss : 0.5377326011657715\n",
            "Epoch(0/1 : Batch number(378/782) : Batch loss : 0.49173831939697266\n",
            "Epoch(0/1 : Batch number(379/782) : Batch loss : 0.3933435082435608\n",
            "Epoch(0/1 : Batch number(380/782) : Batch loss : 0.6687788367271423\n",
            "Epoch(0/1 : Batch number(381/782) : Batch loss : 0.43304765224456787\n",
            "Epoch(0/1 : Batch number(382/782) : Batch loss : 0.5647777915000916\n",
            "Epoch(0/1 : Batch number(383/782) : Batch loss : 0.45149970054626465\n",
            "Epoch(0/1 : Batch number(384/782) : Batch loss : 0.46675726771354675\n",
            "Epoch(0/1 : Batch number(385/782) : Batch loss : 0.5361470580101013\n",
            "Epoch(0/1 : Batch number(386/782) : Batch loss : 0.4842011630535126\n",
            "Epoch(0/1 : Batch number(387/782) : Batch loss : 0.24684669077396393\n",
            "Epoch(0/1 : Batch number(388/782) : Batch loss : 0.4241504967212677\n",
            "Epoch(0/1 : Batch number(389/782) : Batch loss : 0.563809871673584\n",
            "Epoch(0/1 : Batch number(390/782) : Batch loss : 0.5996818542480469\n",
            "Epoch(0/1 : Batch number(391/782) : Batch loss : 0.3490532636642456\n",
            "Epoch(0/1 : Batch number(392/782) : Batch loss : 0.5701720118522644\n",
            "Epoch(0/1 : Batch number(393/782) : Batch loss : 0.38843098282814026\n",
            "Epoch(0/1 : Batch number(394/782) : Batch loss : 0.3261111080646515\n",
            "Epoch(0/1 : Batch number(395/782) : Batch loss : 0.5816884636878967\n",
            "Epoch(0/1 : Batch number(396/782) : Batch loss : 0.3578565716743469\n",
            "Epoch(0/1 : Batch number(397/782) : Batch loss : 0.5393063426017761\n",
            "Epoch(0/1 : Batch number(398/782) : Batch loss : 0.3223126530647278\n",
            "Epoch(0/1 : Batch number(399/782) : Batch loss : 0.6883697509765625\n",
            "Epoch(0/1 : Batch number(400/782) : Batch loss : 0.3411298990249634\n",
            "Epoch(0/1 : Batch number(401/782) : Batch loss : 0.6566479206085205\n",
            "Epoch(0/1 : Batch number(402/782) : Batch loss : 0.7786174416542053\n",
            "Epoch(0/1 : Batch number(403/782) : Batch loss : 0.5923796892166138\n",
            "Epoch(0/1 : Batch number(404/782) : Batch loss : 0.3495780825614929\n",
            "Epoch(0/1 : Batch number(405/782) : Batch loss : 0.4735575318336487\n",
            "Epoch(0/1 : Batch number(406/782) : Batch loss : 0.4593827426433563\n",
            "Epoch(0/1 : Batch number(407/782) : Batch loss : 0.5169731378555298\n",
            "Epoch(0/1 : Batch number(408/782) : Batch loss : 0.3345344662666321\n",
            "Epoch(0/1 : Batch number(409/782) : Batch loss : 0.7443098425865173\n",
            "Epoch(0/1 : Batch number(410/782) : Batch loss : 0.47144410014152527\n",
            "Epoch(0/1 : Batch number(411/782) : Batch loss : 0.5262191295623779\n",
            "Epoch(0/1 : Batch number(412/782) : Batch loss : 0.5589858293533325\n",
            "Epoch(0/1 : Batch number(413/782) : Batch loss : 0.41794389486312866\n",
            "Epoch(0/1 : Batch number(414/782) : Batch loss : 0.4990452527999878\n",
            "Epoch(0/1 : Batch number(415/782) : Batch loss : 0.392296701669693\n",
            "Epoch(0/1 : Batch number(416/782) : Batch loss : 0.7656108736991882\n",
            "Epoch(0/1 : Batch number(417/782) : Batch loss : 0.36928147077560425\n",
            "Epoch(0/1 : Batch number(418/782) : Batch loss : 0.5467413067817688\n",
            "Epoch(0/1 : Batch number(419/782) : Batch loss : 0.4543668329715729\n",
            "Epoch(0/1 : Batch number(420/782) : Batch loss : 0.5888051390647888\n",
            "Epoch(0/1 : Batch number(421/782) : Batch loss : 0.4840565025806427\n",
            "Epoch(0/1 : Batch number(422/782) : Batch loss : 0.573888897895813\n",
            "Epoch(0/1 : Batch number(423/782) : Batch loss : 0.2937797009944916\n",
            "Epoch(0/1 : Batch number(424/782) : Batch loss : 0.4879001975059509\n",
            "Epoch(0/1 : Batch number(425/782) : Batch loss : 0.43270960450172424\n",
            "Epoch(0/1 : Batch number(426/782) : Batch loss : 0.6906600594520569\n",
            "Epoch(0/1 : Batch number(427/782) : Batch loss : 0.4117853343486786\n",
            "Epoch(0/1 : Batch number(428/782) : Batch loss : 0.6795856952667236\n",
            "Epoch(0/1 : Batch number(429/782) : Batch loss : 0.515597403049469\n",
            "Epoch(0/1 : Batch number(430/782) : Batch loss : 0.4958168864250183\n",
            "Epoch(0/1 : Batch number(431/782) : Batch loss : 0.4441812038421631\n",
            "Epoch(0/1 : Batch number(432/782) : Batch loss : 0.38713231682777405\n",
            "Epoch(0/1 : Batch number(433/782) : Batch loss : 0.35751578211784363\n",
            "Epoch(0/1 : Batch number(434/782) : Batch loss : 0.5105053782463074\n",
            "Epoch(0/1 : Batch number(435/782) : Batch loss : 0.39308956265449524\n",
            "Epoch(0/1 : Batch number(436/782) : Batch loss : 0.7392090559005737\n",
            "Epoch(0/1 : Batch number(437/782) : Batch loss : 0.36534151434898376\n",
            "Epoch(0/1 : Batch number(438/782) : Batch loss : 0.45750415325164795\n",
            "Epoch(0/1 : Batch number(439/782) : Batch loss : 0.4074571132659912\n",
            "Epoch(0/1 : Batch number(440/782) : Batch loss : 0.4867081344127655\n",
            "Epoch(0/1 : Batch number(441/782) : Batch loss : 0.2401290237903595\n",
            "Epoch(0/1 : Batch number(442/782) : Batch loss : 0.34479600191116333\n",
            "Epoch(0/1 : Batch number(443/782) : Batch loss : 0.6476244330406189\n",
            "Epoch(0/1 : Batch number(444/782) : Batch loss : 0.6075966358184814\n",
            "Epoch(0/1 : Batch number(445/782) : Batch loss : 0.5579823851585388\n",
            "Epoch(0/1 : Batch number(446/782) : Batch loss : 0.261924684047699\n",
            "Epoch(0/1 : Batch number(447/782) : Batch loss : 0.5840045213699341\n",
            "Epoch(0/1 : Batch number(448/782) : Batch loss : 0.48045065999031067\n",
            "Epoch(0/1 : Batch number(449/782) : Batch loss : 0.40253713726997375\n",
            "Epoch(0/1 : Batch number(450/782) : Batch loss : 0.7146604657173157\n",
            "Epoch(0/1 : Batch number(451/782) : Batch loss : 0.3942939043045044\n",
            "Epoch(0/1 : Batch number(452/782) : Batch loss : 0.5194873809814453\n",
            "Epoch(0/1 : Batch number(453/782) : Batch loss : 0.5402767062187195\n",
            "Epoch(0/1 : Batch number(454/782) : Batch loss : 0.3929169178009033\n",
            "Epoch(0/1 : Batch number(455/782) : Batch loss : 0.5364856123924255\n",
            "Epoch(0/1 : Batch number(456/782) : Batch loss : 0.4594401717185974\n",
            "Epoch(0/1 : Batch number(457/782) : Batch loss : 0.5600137114524841\n",
            "Epoch(0/1 : Batch number(458/782) : Batch loss : 0.5569040775299072\n",
            "Epoch(0/1 : Batch number(459/782) : Batch loss : 0.3059297800064087\n",
            "Epoch(0/1 : Batch number(460/782) : Batch loss : 0.45347291231155396\n",
            "Epoch(0/1 : Batch number(461/782) : Batch loss : 0.4604666829109192\n",
            "Epoch(0/1 : Batch number(462/782) : Batch loss : 0.2454240769147873\n",
            "Epoch(0/1 : Batch number(463/782) : Batch loss : 0.258599191904068\n",
            "Epoch(0/1 : Batch number(464/782) : Batch loss : 0.5087831616401672\n",
            "Epoch(0/1 : Batch number(465/782) : Batch loss : 0.299669086933136\n",
            "Epoch(0/1 : Batch number(466/782) : Batch loss : 0.33463922142982483\n",
            "Epoch(0/1 : Batch number(467/782) : Batch loss : 0.46187981963157654\n",
            "Epoch(0/1 : Batch number(468/782) : Batch loss : 0.48541057109832764\n",
            "Epoch(0/1 : Batch number(469/782) : Batch loss : 0.49232396483421326\n",
            "Epoch(0/1 : Batch number(470/782) : Batch loss : 0.5761670470237732\n",
            "Epoch(0/1 : Batch number(471/782) : Batch loss : 0.42216169834136963\n",
            "Epoch(0/1 : Batch number(472/782) : Batch loss : 0.5016119480133057\n",
            "Epoch(0/1 : Batch number(473/782) : Batch loss : 0.6702576279640198\n",
            "Epoch(0/1 : Batch number(474/782) : Batch loss : 0.3417300283908844\n",
            "Epoch(0/1 : Batch number(475/782) : Batch loss : 0.505260169506073\n",
            "Epoch(0/1 : Batch number(476/782) : Batch loss : 0.36111316084861755\n",
            "Epoch(0/1 : Batch number(477/782) : Batch loss : 0.5437106490135193\n",
            "Epoch(0/1 : Batch number(478/782) : Batch loss : 0.2618637979030609\n",
            "Epoch(0/1 : Batch number(479/782) : Batch loss : 0.4459466338157654\n",
            "Epoch(0/1 : Batch number(480/782) : Batch loss : 0.3795900344848633\n",
            "Epoch(0/1 : Batch number(481/782) : Batch loss : 0.4256459176540375\n",
            "Epoch(0/1 : Batch number(482/782) : Batch loss : 0.5359348058700562\n",
            "Epoch(0/1 : Batch number(483/782) : Batch loss : 0.4787534475326538\n",
            "Epoch(0/1 : Batch number(484/782) : Batch loss : 0.4990229904651642\n",
            "Epoch(0/1 : Batch number(485/782) : Batch loss : 0.3749971389770508\n",
            "Epoch(0/1 : Batch number(486/782) : Batch loss : 0.42137691378593445\n",
            "Epoch(0/1 : Batch number(487/782) : Batch loss : 0.40367552638053894\n",
            "Epoch(0/1 : Batch number(488/782) : Batch loss : 0.46500077843666077\n",
            "Epoch(0/1 : Batch number(489/782) : Batch loss : 0.3927917778491974\n",
            "Epoch(0/1 : Batch number(490/782) : Batch loss : 0.6529704332351685\n",
            "Epoch(0/1 : Batch number(491/782) : Batch loss : 0.32224002480506897\n",
            "Epoch(0/1 : Batch number(492/782) : Batch loss : 0.3834531903266907\n",
            "Epoch(0/1 : Batch number(493/782) : Batch loss : 0.3016854226589203\n",
            "Epoch(0/1 : Batch number(494/782) : Batch loss : 0.608653724193573\n",
            "Epoch(0/1 : Batch number(495/782) : Batch loss : 0.39648619294166565\n",
            "Epoch(0/1 : Batch number(496/782) : Batch loss : 0.3779279291629791\n",
            "Epoch(0/1 : Batch number(497/782) : Batch loss : 0.3130917251110077\n",
            "Epoch(0/1 : Batch number(498/782) : Batch loss : 0.6020640730857849\n",
            "Epoch(0/1 : Batch number(499/782) : Batch loss : 0.4920828640460968\n",
            "Epoch(0/1 : Batch number(500/782) : Batch loss : 0.35867762565612793\n",
            "Epoch(0/1 : Batch number(501/782) : Batch loss : 0.3964764475822449\n",
            "Epoch(0/1 : Batch number(502/782) : Batch loss : 0.4403819441795349\n",
            "Epoch(0/1 : Batch number(503/782) : Batch loss : 0.5591270327568054\n",
            "Epoch(0/1 : Batch number(504/782) : Batch loss : 0.5708804130554199\n",
            "Epoch(0/1 : Batch number(505/782) : Batch loss : 0.3988860249519348\n",
            "Epoch(0/1 : Batch number(506/782) : Batch loss : 0.4436136484146118\n",
            "Epoch(0/1 : Batch number(507/782) : Batch loss : 0.2763160169124603\n",
            "Epoch(0/1 : Batch number(508/782) : Batch loss : 0.29580795764923096\n",
            "Epoch(0/1 : Batch number(509/782) : Batch loss : 0.41136249899864197\n",
            "Epoch(0/1 : Batch number(510/782) : Batch loss : 0.43913859128952026\n",
            "Epoch(0/1 : Batch number(511/782) : Batch loss : 0.4522346258163452\n",
            "Epoch(0/1 : Batch number(512/782) : Batch loss : 0.2877836525440216\n",
            "Epoch(0/1 : Batch number(513/782) : Batch loss : 0.45652636885643005\n",
            "Epoch(0/1 : Batch number(514/782) : Batch loss : 0.5440894961357117\n",
            "Epoch(0/1 : Batch number(515/782) : Batch loss : 0.5444086194038391\n",
            "Epoch(0/1 : Batch number(516/782) : Batch loss : 0.5989793539047241\n",
            "Epoch(0/1 : Batch number(517/782) : Batch loss : 0.2708616554737091\n",
            "Epoch(0/1 : Batch number(518/782) : Batch loss : 0.5482228398323059\n",
            "Epoch(0/1 : Batch number(519/782) : Batch loss : 0.22801998257637024\n",
            "Epoch(0/1 : Batch number(520/782) : Batch loss : 0.4684154987335205\n",
            "Epoch(0/1 : Batch number(521/782) : Batch loss : 0.35593941807746887\n",
            "Epoch(0/1 : Batch number(522/782) : Batch loss : 0.379117876291275\n",
            "Epoch(0/1 : Batch number(523/782) : Batch loss : 0.3518434762954712\n",
            "Epoch(0/1 : Batch number(524/782) : Batch loss : 0.48638105392456055\n",
            "Epoch(0/1 : Batch number(525/782) : Batch loss : 0.35463306307792664\n",
            "Epoch(0/1 : Batch number(526/782) : Batch loss : 0.5037761926651001\n",
            "Epoch(0/1 : Batch number(527/782) : Batch loss : 0.46149665117263794\n",
            "Epoch(0/1 : Batch number(528/782) : Batch loss : 0.4684023857116699\n",
            "Epoch(0/1 : Batch number(529/782) : Batch loss : 0.39035260677337646\n",
            "Epoch(0/1 : Batch number(530/782) : Batch loss : 0.4522390365600586\n",
            "Epoch(0/1 : Batch number(531/782) : Batch loss : 0.6150599718093872\n",
            "Epoch(0/1 : Batch number(532/782) : Batch loss : 0.37251242995262146\n",
            "Epoch(0/1 : Batch number(533/782) : Batch loss : 0.6334568858146667\n",
            "Epoch(0/1 : Batch number(534/782) : Batch loss : 0.5451016426086426\n",
            "Epoch(0/1 : Batch number(535/782) : Batch loss : 0.33961912989616394\n",
            "Epoch(0/1 : Batch number(536/782) : Batch loss : 0.5004790425300598\n",
            "Epoch(0/1 : Batch number(537/782) : Batch loss : 0.38778156042099\n",
            "Epoch(0/1 : Batch number(538/782) : Batch loss : 0.6675463914871216\n",
            "Epoch(0/1 : Batch number(539/782) : Batch loss : 0.523177444934845\n",
            "Epoch(0/1 : Batch number(540/782) : Batch loss : 0.41065913438796997\n",
            "Epoch(0/1 : Batch number(541/782) : Batch loss : 0.21856828033924103\n",
            "Epoch(0/1 : Batch number(542/782) : Batch loss : 0.42202502489089966\n",
            "Epoch(0/1 : Batch number(543/782) : Batch loss : 0.41097334027290344\n",
            "Epoch(0/1 : Batch number(544/782) : Batch loss : 0.43417608737945557\n",
            "Epoch(0/1 : Batch number(545/782) : Batch loss : 0.4279197156429291\n",
            "Epoch(0/1 : Batch number(546/782) : Batch loss : 0.4922875165939331\n",
            "Epoch(0/1 : Batch number(547/782) : Batch loss : 0.4894588887691498\n",
            "Epoch(0/1 : Batch number(548/782) : Batch loss : 0.40185731649398804\n",
            "Epoch(0/1 : Batch number(549/782) : Batch loss : 0.6105270981788635\n",
            "Epoch(0/1 : Batch number(550/782) : Batch loss : 0.6009356379508972\n",
            "Epoch(0/1 : Batch number(551/782) : Batch loss : 0.48846250772476196\n",
            "Epoch(0/1 : Batch number(552/782) : Batch loss : 0.5385410189628601\n",
            "Epoch(0/1 : Batch number(553/782) : Batch loss : 0.39768221974372864\n",
            "Epoch(0/1 : Batch number(554/782) : Batch loss : 0.785926342010498\n",
            "Epoch(0/1 : Batch number(555/782) : Batch loss : 0.5619896650314331\n",
            "Epoch(0/1 : Batch number(556/782) : Batch loss : 0.3879415988922119\n",
            "Epoch(0/1 : Batch number(557/782) : Batch loss : 0.3477247953414917\n",
            "Epoch(0/1 : Batch number(558/782) : Batch loss : 0.3975721299648285\n",
            "Epoch(0/1 : Batch number(559/782) : Batch loss : 0.16829364001750946\n",
            "Epoch(0/1 : Batch number(560/782) : Batch loss : 0.44677427411079407\n",
            "Epoch(0/1 : Batch number(561/782) : Batch loss : 0.601760745048523\n",
            "Epoch(0/1 : Batch number(562/782) : Batch loss : 0.48156848549842834\n",
            "Epoch(0/1 : Batch number(563/782) : Batch loss : 0.3606320917606354\n",
            "Epoch(0/1 : Batch number(564/782) : Batch loss : 0.6118436455726624\n",
            "Epoch(0/1 : Batch number(565/782) : Batch loss : 0.6338840126991272\n",
            "Epoch(0/1 : Batch number(566/782) : Batch loss : 0.5038411617279053\n",
            "Epoch(0/1 : Batch number(567/782) : Batch loss : 0.3904341459274292\n",
            "Epoch(0/1 : Batch number(568/782) : Batch loss : 0.692654013633728\n",
            "Epoch(0/1 : Batch number(569/782) : Batch loss : 0.353618323802948\n",
            "Epoch(0/1 : Batch number(570/782) : Batch loss : 0.6055536866188049\n",
            "Epoch(0/1 : Batch number(571/782) : Batch loss : 0.4160560667514801\n",
            "Epoch(0/1 : Batch number(572/782) : Batch loss : 0.35455122590065\n",
            "Epoch(0/1 : Batch number(573/782) : Batch loss : 0.7275367379188538\n",
            "Epoch(0/1 : Batch number(574/782) : Batch loss : 0.28199735283851624\n",
            "Epoch(0/1 : Batch number(575/782) : Batch loss : 0.5557740926742554\n",
            "Epoch(0/1 : Batch number(576/782) : Batch loss : 0.40809446573257446\n",
            "Epoch(0/1 : Batch number(577/782) : Batch loss : 0.5276359915733337\n",
            "Epoch(0/1 : Batch number(578/782) : Batch loss : 0.5384833216667175\n",
            "Epoch(0/1 : Batch number(579/782) : Batch loss : 0.4688551425933838\n",
            "Epoch(0/1 : Batch number(580/782) : Batch loss : 0.4236837327480316\n",
            "Epoch(0/1 : Batch number(581/782) : Batch loss : 0.41530781984329224\n",
            "Epoch(0/1 : Batch number(582/782) : Batch loss : 0.39302098751068115\n",
            "Epoch(0/1 : Batch number(583/782) : Batch loss : 0.47863802313804626\n",
            "Epoch(0/1 : Batch number(584/782) : Batch loss : 0.5197411775588989\n",
            "Epoch(0/1 : Batch number(585/782) : Batch loss : 0.3475070595741272\n",
            "Epoch(0/1 : Batch number(586/782) : Batch loss : 0.4974525272846222\n",
            "Epoch(0/1 : Batch number(587/782) : Batch loss : 0.7389625310897827\n",
            "Epoch(0/1 : Batch number(588/782) : Batch loss : 0.741469144821167\n",
            "Epoch(0/1 : Batch number(589/782) : Batch loss : 0.40310126543045044\n",
            "Epoch(0/1 : Batch number(590/782) : Batch loss : 0.5481564402580261\n",
            "Epoch(0/1 : Batch number(591/782) : Batch loss : 0.41348734498023987\n",
            "Epoch(0/1 : Batch number(592/782) : Batch loss : 0.32040321826934814\n",
            "Epoch(0/1 : Batch number(593/782) : Batch loss : 0.37427371740341187\n",
            "Epoch(0/1 : Batch number(594/782) : Batch loss : 0.3775602877140045\n",
            "Epoch(0/1 : Batch number(595/782) : Batch loss : 0.6222026348114014\n",
            "Epoch(0/1 : Batch number(596/782) : Batch loss : 0.5025697350502014\n",
            "Epoch(0/1 : Batch number(597/782) : Batch loss : 0.41949543356895447\n",
            "Epoch(0/1 : Batch number(598/782) : Batch loss : 0.5723493099212646\n",
            "Epoch(0/1 : Batch number(599/782) : Batch loss : 0.5528988242149353\n",
            "Epoch(0/1 : Batch number(600/782) : Batch loss : 0.38990652561187744\n",
            "Epoch(0/1 : Batch number(601/782) : Batch loss : 0.6612759232521057\n",
            "Epoch(0/1 : Batch number(602/782) : Batch loss : 0.4596344828605652\n",
            "Epoch(0/1 : Batch number(603/782) : Batch loss : 0.3298170566558838\n",
            "Epoch(0/1 : Batch number(604/782) : Batch loss : 0.4534575045108795\n",
            "Epoch(0/1 : Batch number(605/782) : Batch loss : 0.4083459973335266\n",
            "Epoch(0/1 : Batch number(606/782) : Batch loss : 0.40698638558387756\n",
            "Epoch(0/1 : Batch number(607/782) : Batch loss : 0.4006734788417816\n",
            "Epoch(0/1 : Batch number(608/782) : Batch loss : 0.5082322955131531\n",
            "Epoch(0/1 : Batch number(609/782) : Batch loss : 0.5682304501533508\n",
            "Epoch(0/1 : Batch number(610/782) : Batch loss : 0.5065507292747498\n",
            "Epoch(0/1 : Batch number(611/782) : Batch loss : 0.4022819995880127\n",
            "Epoch(0/1 : Batch number(612/782) : Batch loss : 0.3324607312679291\n",
            "Epoch(0/1 : Batch number(613/782) : Batch loss : 0.5052517056465149\n",
            "Epoch(0/1 : Batch number(614/782) : Batch loss : 0.35477593541145325\n",
            "Epoch(0/1 : Batch number(615/782) : Batch loss : 0.5091533064842224\n",
            "Epoch(0/1 : Batch number(616/782) : Batch loss : 0.4453965425491333\n",
            "Epoch(0/1 : Batch number(617/782) : Batch loss : 0.36869028210639954\n",
            "Epoch(0/1 : Batch number(618/782) : Batch loss : 0.5624765157699585\n",
            "Epoch(0/1 : Batch number(619/782) : Batch loss : 0.3418813943862915\n",
            "Epoch(0/1 : Batch number(620/782) : Batch loss : 0.5754483938217163\n",
            "Epoch(0/1 : Batch number(621/782) : Batch loss : 0.44119662046432495\n",
            "Epoch(0/1 : Batch number(622/782) : Batch loss : 0.41016843914985657\n",
            "Epoch(0/1 : Batch number(623/782) : Batch loss : 0.6029014587402344\n",
            "Epoch(0/1 : Batch number(624/782) : Batch loss : 0.3576182425022125\n",
            "Epoch(0/1 : Batch number(625/782) : Batch loss : 0.3818418085575104\n",
            "Epoch(0/1 : Batch number(626/782) : Batch loss : 0.4716585874557495\n",
            "Epoch(0/1 : Batch number(627/782) : Batch loss : 0.5694044828414917\n",
            "Epoch(0/1 : Batch number(628/782) : Batch loss : 0.47584953904151917\n",
            "Epoch(0/1 : Batch number(629/782) : Batch loss : 0.3671873211860657\n",
            "Epoch(0/1 : Batch number(630/782) : Batch loss : 0.5616756677627563\n",
            "Epoch(0/1 : Batch number(631/782) : Batch loss : 0.40387776494026184\n",
            "Epoch(0/1 : Batch number(632/782) : Batch loss : 0.4345519244670868\n",
            "Epoch(0/1 : Batch number(633/782) : Batch loss : 0.5176968574523926\n",
            "Epoch(0/1 : Batch number(634/782) : Batch loss : 0.6847920417785645\n",
            "Epoch(0/1 : Batch number(635/782) : Batch loss : 0.41137537360191345\n",
            "Epoch(0/1 : Batch number(636/782) : Batch loss : 0.6993979811668396\n",
            "Epoch(0/1 : Batch number(637/782) : Batch loss : 0.431746244430542\n",
            "Epoch(0/1 : Batch number(638/782) : Batch loss : 0.2393859177827835\n",
            "Epoch(0/1 : Batch number(639/782) : Batch loss : 0.569301187992096\n",
            "Epoch(0/1 : Batch number(640/782) : Batch loss : 0.5233063697814941\n",
            "Epoch(0/1 : Batch number(641/782) : Batch loss : 0.5868929028511047\n",
            "Epoch(0/1 : Batch number(642/782) : Batch loss : 0.43409407138824463\n",
            "Epoch(0/1 : Batch number(643/782) : Batch loss : 0.3898741602897644\n",
            "Epoch(0/1 : Batch number(644/782) : Batch loss : 0.5644088983535767\n",
            "Epoch(0/1 : Batch number(645/782) : Batch loss : 0.28269773721694946\n",
            "Epoch(0/1 : Batch number(646/782) : Batch loss : 0.5219032764434814\n",
            "Epoch(0/1 : Batch number(647/782) : Batch loss : 0.6051032543182373\n",
            "Epoch(0/1 : Batch number(648/782) : Batch loss : 0.5241321325302124\n",
            "Epoch(0/1 : Batch number(649/782) : Batch loss : 0.5208900570869446\n",
            "Epoch(0/1 : Batch number(650/782) : Batch loss : 0.46725529432296753\n",
            "Epoch(0/1 : Batch number(651/782) : Batch loss : 0.6205549240112305\n",
            "Epoch(0/1 : Batch number(652/782) : Batch loss : 0.5284030437469482\n",
            "Epoch(0/1 : Batch number(653/782) : Batch loss : 0.5208715200424194\n",
            "Epoch(0/1 : Batch number(654/782) : Batch loss : 0.39082470536231995\n",
            "Epoch(0/1 : Batch number(655/782) : Batch loss : 0.5171915292739868\n",
            "Epoch(0/1 : Batch number(656/782) : Batch loss : 0.42965424060821533\n",
            "Epoch(0/1 : Batch number(657/782) : Batch loss : 0.5566015243530273\n",
            "Epoch(0/1 : Batch number(658/782) : Batch loss : 0.4891478717327118\n",
            "Epoch(0/1 : Batch number(659/782) : Batch loss : 0.47437113523483276\n",
            "Epoch(0/1 : Batch number(660/782) : Batch loss : 0.5937626957893372\n",
            "Epoch(0/1 : Batch number(661/782) : Batch loss : 0.42512840032577515\n",
            "Epoch(0/1 : Batch number(662/782) : Batch loss : 0.3111167252063751\n",
            "Epoch(0/1 : Batch number(663/782) : Batch loss : 0.5868269801139832\n",
            "Epoch(0/1 : Batch number(664/782) : Batch loss : 0.6387127041816711\n",
            "Epoch(0/1 : Batch number(665/782) : Batch loss : 0.4877574145793915\n",
            "Epoch(0/1 : Batch number(666/782) : Batch loss : 0.5019326210021973\n",
            "Epoch(0/1 : Batch number(667/782) : Batch loss : 0.45902836322784424\n",
            "Epoch(0/1 : Batch number(668/782) : Batch loss : 0.37522557377815247\n",
            "Epoch(0/1 : Batch number(669/782) : Batch loss : 0.4530027210712433\n",
            "Epoch(0/1 : Batch number(670/782) : Batch loss : 0.3338479995727539\n",
            "Epoch(0/1 : Batch number(671/782) : Batch loss : 0.3523370921611786\n",
            "Epoch(0/1 : Batch number(672/782) : Batch loss : 0.4098047912120819\n",
            "Epoch(0/1 : Batch number(673/782) : Batch loss : 0.41712918877601624\n",
            "Epoch(0/1 : Batch number(674/782) : Batch loss : 0.5849195122718811\n",
            "Epoch(0/1 : Batch number(675/782) : Batch loss : 0.42828306555747986\n",
            "Epoch(0/1 : Batch number(676/782) : Batch loss : 0.3221951723098755\n",
            "Epoch(0/1 : Batch number(677/782) : Batch loss : 0.296790212392807\n",
            "Epoch(0/1 : Batch number(678/782) : Batch loss : 0.32845446467399597\n",
            "Epoch(0/1 : Batch number(679/782) : Batch loss : 0.44253748655319214\n",
            "Epoch(0/1 : Batch number(680/782) : Batch loss : 0.46207454800605774\n",
            "Epoch(0/1 : Batch number(681/782) : Batch loss : 0.44036296010017395\n",
            "Epoch(0/1 : Batch number(682/782) : Batch loss : 0.5180128216743469\n",
            "Epoch(0/1 : Batch number(683/782) : Batch loss : 0.4458869695663452\n",
            "Epoch(0/1 : Batch number(684/782) : Batch loss : 0.46136072278022766\n",
            "Epoch(0/1 : Batch number(685/782) : Batch loss : 0.47845709323883057\n",
            "Epoch(0/1 : Batch number(686/782) : Batch loss : 0.515637993812561\n",
            "Epoch(0/1 : Batch number(687/782) : Batch loss : 0.46935346722602844\n",
            "Epoch(0/1 : Batch number(688/782) : Batch loss : 0.5622034072875977\n",
            "Epoch(0/1 : Batch number(689/782) : Batch loss : 0.7063192129135132\n",
            "Epoch(0/1 : Batch number(690/782) : Batch loss : 0.21445973217487335\n",
            "Epoch(0/1 : Batch number(691/782) : Batch loss : 0.5911078453063965\n",
            "Epoch(0/1 : Batch number(692/782) : Batch loss : 0.4326803684234619\n",
            "Epoch(0/1 : Batch number(693/782) : Batch loss : 0.4133932888507843\n",
            "Epoch(0/1 : Batch number(694/782) : Batch loss : 0.4037264585494995\n",
            "Epoch(0/1 : Batch number(695/782) : Batch loss : 0.3456033766269684\n",
            "Epoch(0/1 : Batch number(696/782) : Batch loss : 0.43652281165122986\n",
            "Epoch(0/1 : Batch number(697/782) : Batch loss : 0.4075242578983307\n",
            "Epoch(0/1 : Batch number(698/782) : Batch loss : 0.5431379675865173\n",
            "Epoch(0/1 : Batch number(699/782) : Batch loss : 0.33550143241882324\n",
            "Epoch(0/1 : Batch number(700/782) : Batch loss : 0.4019055962562561\n",
            "Epoch(0/1 : Batch number(701/782) : Batch loss : 0.3998510539531708\n",
            "Epoch(0/1 : Batch number(702/782) : Batch loss : 0.49821123480796814\n",
            "Epoch(0/1 : Batch number(703/782) : Batch loss : 0.46979281306266785\n",
            "Epoch(0/1 : Batch number(704/782) : Batch loss : 0.5526167750358582\n",
            "Epoch(0/1 : Batch number(705/782) : Batch loss : 0.42271021008491516\n",
            "Epoch(0/1 : Batch number(706/782) : Batch loss : 0.6176096200942993\n",
            "Epoch(0/1 : Batch number(707/782) : Batch loss : 0.31037333607673645\n",
            "Epoch(0/1 : Batch number(708/782) : Batch loss : 0.41452065110206604\n",
            "Epoch(0/1 : Batch number(709/782) : Batch loss : 0.3199233114719391\n",
            "Epoch(0/1 : Batch number(710/782) : Batch loss : 0.35777801275253296\n",
            "Epoch(0/1 : Batch number(711/782) : Batch loss : 0.6394655108451843\n",
            "Epoch(0/1 : Batch number(712/782) : Batch loss : 0.511872410774231\n",
            "Epoch(0/1 : Batch number(713/782) : Batch loss : 0.3453502953052521\n",
            "Epoch(0/1 : Batch number(714/782) : Batch loss : 0.34634116291999817\n",
            "Epoch(0/1 : Batch number(715/782) : Batch loss : 0.28148430585861206\n",
            "Epoch(0/1 : Batch number(716/782) : Batch loss : 0.32621538639068604\n",
            "Epoch(0/1 : Batch number(717/782) : Batch loss : 0.5105561017990112\n",
            "Epoch(0/1 : Batch number(718/782) : Batch loss : 0.43107327818870544\n",
            "Epoch(0/1 : Batch number(719/782) : Batch loss : 0.35278064012527466\n",
            "Epoch(0/1 : Batch number(720/782) : Batch loss : 0.3890223801136017\n",
            "Epoch(0/1 : Batch number(721/782) : Batch loss : 0.5968095660209656\n",
            "Epoch(0/1 : Batch number(722/782) : Batch loss : 0.4293179214000702\n",
            "Epoch(0/1 : Batch number(723/782) : Batch loss : 0.2951998710632324\n",
            "Epoch(0/1 : Batch number(724/782) : Batch loss : 0.4079044759273529\n",
            "Epoch(0/1 : Batch number(725/782) : Batch loss : 0.6050050258636475\n",
            "Epoch(0/1 : Batch number(726/782) : Batch loss : 0.39875558018684387\n",
            "Epoch(0/1 : Batch number(727/782) : Batch loss : 0.45523160696029663\n",
            "Epoch(0/1 : Batch number(728/782) : Batch loss : 0.495365172624588\n",
            "Epoch(0/1 : Batch number(729/782) : Batch loss : 0.4167812168598175\n",
            "Epoch(0/1 : Batch number(730/782) : Batch loss : 0.4844045042991638\n",
            "Epoch(0/1 : Batch number(731/782) : Batch loss : 0.5685579180717468\n",
            "Epoch(0/1 : Batch number(732/782) : Batch loss : 0.5510551929473877\n",
            "Epoch(0/1 : Batch number(733/782) : Batch loss : 0.5730338096618652\n",
            "Epoch(0/1 : Batch number(734/782) : Batch loss : 0.4122363030910492\n",
            "Epoch(0/1 : Batch number(735/782) : Batch loss : 0.6274898052215576\n",
            "Epoch(0/1 : Batch number(736/782) : Batch loss : 0.41631001234054565\n",
            "Epoch(0/1 : Batch number(737/782) : Batch loss : 0.4388763904571533\n",
            "Epoch(0/1 : Batch number(738/782) : Batch loss : 0.29384705424308777\n",
            "Epoch(0/1 : Batch number(739/782) : Batch loss : 0.4215640425682068\n",
            "Epoch(0/1 : Batch number(740/782) : Batch loss : 0.6284527778625488\n",
            "Epoch(0/1 : Batch number(741/782) : Batch loss : 0.5829184055328369\n",
            "Epoch(0/1 : Batch number(742/782) : Batch loss : 0.3789106011390686\n",
            "Epoch(0/1 : Batch number(743/782) : Batch loss : 0.5313305258750916\n",
            "Epoch(0/1 : Batch number(744/782) : Batch loss : 0.5318560600280762\n",
            "Epoch(0/1 : Batch number(745/782) : Batch loss : 0.3472222685813904\n",
            "Epoch(0/1 : Batch number(746/782) : Batch loss : 0.4475475251674652\n",
            "Epoch(0/1 : Batch number(747/782) : Batch loss : 0.7292953133583069\n",
            "Epoch(0/1 : Batch number(748/782) : Batch loss : 0.45553237199783325\n",
            "Epoch(0/1 : Batch number(749/782) : Batch loss : 0.3080034852027893\n",
            "Epoch(0/1 : Batch number(750/782) : Batch loss : 0.5658656358718872\n",
            "Epoch(0/1 : Batch number(751/782) : Batch loss : 0.48814794421195984\n",
            "Epoch(0/1 : Batch number(752/782) : Batch loss : 0.3275628983974457\n",
            "Epoch(0/1 : Batch number(753/782) : Batch loss : 0.3799194395542145\n",
            "Epoch(0/1 : Batch number(754/782) : Batch loss : 0.36207315325737\n",
            "Epoch(0/1 : Batch number(755/782) : Batch loss : 0.3795931339263916\n",
            "Epoch(0/1 : Batch number(756/782) : Batch loss : 0.40015095472335815\n",
            "Epoch(0/1 : Batch number(757/782) : Batch loss : 0.667582094669342\n",
            "Epoch(0/1 : Batch number(758/782) : Batch loss : 0.45945149660110474\n",
            "Epoch(0/1 : Batch number(759/782) : Batch loss : 0.5164890289306641\n",
            "Epoch(0/1 : Batch number(760/782) : Batch loss : 0.49820590019226074\n",
            "Epoch(0/1 : Batch number(761/782) : Batch loss : 0.6050481200218201\n",
            "Epoch(0/1 : Batch number(762/782) : Batch loss : 0.3913610875606537\n",
            "Epoch(0/1 : Batch number(763/782) : Batch loss : 0.5774512887001038\n",
            "Epoch(0/1 : Batch number(764/782) : Batch loss : 0.45769765973091125\n",
            "Epoch(0/1 : Batch number(765/782) : Batch loss : 0.5657159686088562\n",
            "Epoch(0/1 : Batch number(766/782) : Batch loss : 0.5490620732307434\n",
            "Epoch(0/1 : Batch number(767/782) : Batch loss : 0.5680308938026428\n",
            "Epoch(0/1 : Batch number(768/782) : Batch loss : 0.3793542683124542\n",
            "Epoch(0/1 : Batch number(769/782) : Batch loss : 0.2929195165634155\n",
            "Epoch(0/1 : Batch number(770/782) : Batch loss : 0.2906624674797058\n",
            "Epoch(0/1 : Batch number(771/782) : Batch loss : 0.27252769470214844\n",
            "Epoch(0/1 : Batch number(772/782) : Batch loss : 0.3787476122379303\n",
            "Epoch(0/1 : Batch number(773/782) : Batch loss : 0.3539921045303345\n",
            "Epoch(0/1 : Batch number(774/782) : Batch loss : 0.6362835168838501\n",
            "Epoch(0/1 : Batch number(775/782) : Batch loss : 0.3407036066055298\n",
            "Epoch(0/1 : Batch number(776/782) : Batch loss : 0.523327112197876\n",
            "Epoch(0/1 : Batch number(777/782) : Batch loss : 0.5167177319526672\n",
            "Epoch(0/1 : Batch number(778/782) : Batch loss : 0.299136221408844\n",
            "Epoch(0/1 : Batch number(779/782) : Batch loss : 0.542343020439148\n",
            "Epoch(0/1 : Batch number(780/782) : Batch loss : 0.3709935247898102\n",
            "Epoch(0/1 : Batch number(781/782) : Batch loss : 0.46387284994125366\n",
            "Epoch(0/1 : Batch number(782/782) : Batch loss : 0.6079421639442444\n",
            "Training loss : 0.49522912433690125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_RCnNg9rV7"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoeCTt29rV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a23675-3978-4aae-e0ec-8aa13bbbc0e6"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch (1/157)\n",
            "Batch (2/157)\n",
            "Batch (3/157)\n",
            "Batch (4/157)\n",
            "Batch (5/157)\n",
            "Accuracy of the model on 320 test images: 83.125% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}