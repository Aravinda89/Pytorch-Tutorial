{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b303116f39bb49a6bd0982d1ded1a884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04660d5fffb94267a8698a52c1cefcf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0faf020a486343acb1df301a9aa8663e",
              "IPY_MODEL_40f87276553a4544bd6c8c864683312f"
            ]
          }
        },
        "04660d5fffb94267a8698a52c1cefcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0faf020a486343acb1df301a9aa8663e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_343abd6d38f0455a88ad032fc68211cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5160cfceffb4863b08aea8c80eacc32"
          }
        },
        "40f87276553a4544bd6c8c864683312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04ada32028304f4b9a310648269ab727",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [11:48&lt;00:00, 240705.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f88cd115f5df40e8b323379ac34dd076"
          }
        },
        "343abd6d38f0455a88ad032fc68211cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5160cfceffb4863b08aea8c80eacc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04ada32028304f4b9a310648269ab727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f88cd115f5df40e8b323379ac34dd076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ac22de5feba4ae4b55b05a5e58caa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82b83f7369ca43d1a4c9d66407aa16b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b94d94de815342efa97b4d417c516924",
              "IPY_MODEL_81636d80335c4033b497e25a4a57f793"
            ]
          }
        },
        "82b83f7369ca43d1a4c9d66407aa16b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b94d94de815342efa97b4d417c516924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83bff0e6052043b8aa828397662bd763",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9948c909165486f92b378a5f3cea3a4"
          }
        },
        "81636d80335c4033b497e25a4a57f793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_623302fb44c642828d13561303ce9efe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [11:31&lt;00:00, 800kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0380b70d8d854418ad078f6f2215da72"
          }
        },
        "83bff0e6052043b8aa828397662bd763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9948c909165486f92b378a5f3cea3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "623302fb44c642828d13561303ce9efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0380b70d8d854418ad078f6f2215da72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravinda89/Pytorch-Tutorial/blob/main/Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z2kILHRWcKg"
      },
      "source": [
        "# Transfer learning - Fine-tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggcpfBwQcU8"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3w2sce8WXYa"
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDchYyEo5Fe"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYMYVmxMpX2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf14779-8301-479d-97e3-09c6658372e2"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEw9S-Up23y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "b303116f39bb49a6bd0982d1ded1a884",
            "04660d5fffb94267a8698a52c1cefcf8",
            "0faf020a486343acb1df301a9aa8663e",
            "40f87276553a4544bd6c8c864683312f",
            "343abd6d38f0455a88ad032fc68211cf",
            "b5160cfceffb4863b08aea8c80eacc32",
            "04ada32028304f4b9a310648269ab727",
            "f88cd115f5df40e8b323379ac34dd076"
          ]
        },
        "outputId": "01eaae7a-da64-40f5-cf56-97f2d027af98"
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=True, download=True,transform=transform)\n",
        "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=False, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b303116f39bb49a6bd0982d1ded1a884",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /root/.pytorch/CIFAR10/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1CRA2mdqZ8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e273a14-f528-4b43-c734-e8967f3e021f"
      },
      "source": [
        "for images, labels in trainloader:\n",
        "  print(images.size(), labels.size())\n",
        "  break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBchPi4jvHMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881,
          "referenced_widgets": [
            "8ac22de5feba4ae4b55b05a5e58caa6c",
            "82b83f7369ca43d1a4c9d66407aa16b9",
            "b94d94de815342efa97b4d417c516924",
            "81636d80335c4033b497e25a4a57f793",
            "83bff0e6052043b8aa828397662bd763",
            "a9948c909165486f92b378a5f3cea3a4",
            "623302fb44c642828d13561303ce9efe",
            "0380b70d8d854418ad078f6f2215da72"
          ]
        },
        "outputId": "4612e075-03d6-4980-83bb-aa8059a850d6"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac22de5feba4ae4b55b05a5e58caa6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avx6J-_Mvfy3"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7URaKbIwhse"
      },
      "source": [
        "for i in range(0,7):\n",
        "  model.classifier[i].requires_grad = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-rCUHPiY3c",
        "outputId": "9fda9b16-7f09-4be2-ea4b-f4d0742b2f6e"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (4): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sBWZLtJwt3P"
      },
      "source": [
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(4096,512),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.5),\n",
        "                      nn.Linear(512,10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                      )\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXPMdB3b-9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957c43de-e04f-4357-de97-50b74a2caffb"
      },
      "source": [
        "model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "      (4): LogSoftmax(dim=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IGZ_qw9NA8u"
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9-eEGnxW77"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = Adam(model.parameters())\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vamBkzek_ZfR"
      },
      "source": [
        "## Training from the Fully Connected Network onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3WWNZkQ_ZfS"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ-xpFU-_ZfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bce1f9-e302-4421-e3ce-24baf45e3b37"
      },
      "source": [
        "model = model.to(device)\n",
        "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch(0/1 : Batch number(1/782) : Batch loss : 2.361457347869873\n",
            "Epoch(0/1 : Batch number(2/782) : Batch loss : 2.156857967376709\n",
            "Epoch(0/1 : Batch number(3/782) : Batch loss : 2.081439256668091\n",
            "Epoch(0/1 : Batch number(4/782) : Batch loss : 1.7626581192016602\n",
            "Epoch(0/1 : Batch number(5/782) : Batch loss : 1.5858782529830933\n",
            "Epoch(0/1 : Batch number(6/782) : Batch loss : 1.4446852207183838\n",
            "Epoch(0/1 : Batch number(7/782) : Batch loss : 1.3939170837402344\n",
            "Epoch(0/1 : Batch number(8/782) : Batch loss : 1.2063090801239014\n",
            "Epoch(0/1 : Batch number(9/782) : Batch loss : 1.1869242191314697\n",
            "Epoch(0/1 : Batch number(10/782) : Batch loss : 0.8906316757202148\n",
            "Epoch(0/1 : Batch number(11/782) : Batch loss : 0.9882822036743164\n",
            "Epoch(0/1 : Batch number(12/782) : Batch loss : 0.8890610337257385\n",
            "Epoch(0/1 : Batch number(13/782) : Batch loss : 0.9528430700302124\n",
            "Epoch(0/1 : Batch number(14/782) : Batch loss : 0.8607155680656433\n",
            "Epoch(0/1 : Batch number(15/782) : Batch loss : 0.8540244698524475\n",
            "Epoch(0/1 : Batch number(16/782) : Batch loss : 0.9269976615905762\n",
            "Epoch(0/1 : Batch number(17/782) : Batch loss : 1.227453351020813\n",
            "Epoch(0/1 : Batch number(18/782) : Batch loss : 1.055867314338684\n",
            "Epoch(0/1 : Batch number(19/782) : Batch loss : 1.0373754501342773\n",
            "Epoch(0/1 : Batch number(20/782) : Batch loss : 1.0138720273971558\n",
            "Epoch(0/1 : Batch number(21/782) : Batch loss : 1.0780141353607178\n",
            "Epoch(0/1 : Batch number(22/782) : Batch loss : 0.6358468532562256\n",
            "Epoch(0/1 : Batch number(23/782) : Batch loss : 1.0768617391586304\n",
            "Epoch(0/1 : Batch number(24/782) : Batch loss : 1.0379563570022583\n",
            "Epoch(0/1 : Batch number(25/782) : Batch loss : 0.8704649806022644\n",
            "Epoch(0/1 : Batch number(26/782) : Batch loss : 0.8005847334861755\n",
            "Epoch(0/1 : Batch number(27/782) : Batch loss : 1.0272828340530396\n",
            "Epoch(0/1 : Batch number(28/782) : Batch loss : 0.9403524398803711\n",
            "Epoch(0/1 : Batch number(29/782) : Batch loss : 0.710517406463623\n",
            "Epoch(0/1 : Batch number(30/782) : Batch loss : 0.7449744343757629\n",
            "Epoch(0/1 : Batch number(31/782) : Batch loss : 0.7262617349624634\n",
            "Epoch(0/1 : Batch number(32/782) : Batch loss : 1.033623456954956\n",
            "Epoch(0/1 : Batch number(33/782) : Batch loss : 1.1665775775909424\n",
            "Epoch(0/1 : Batch number(34/782) : Batch loss : 1.0459649562835693\n",
            "Epoch(0/1 : Batch number(35/782) : Batch loss : 0.717766523361206\n",
            "Epoch(0/1 : Batch number(36/782) : Batch loss : 0.8045527338981628\n",
            "Epoch(0/1 : Batch number(37/782) : Batch loss : 0.9831715226173401\n",
            "Epoch(0/1 : Batch number(38/782) : Batch loss : 1.315159797668457\n",
            "Epoch(0/1 : Batch number(39/782) : Batch loss : 0.7577829957008362\n",
            "Epoch(0/1 : Batch number(40/782) : Batch loss : 1.115103006362915\n",
            "Epoch(0/1 : Batch number(41/782) : Batch loss : 0.7408742904663086\n",
            "Epoch(0/1 : Batch number(42/782) : Batch loss : 1.0378421545028687\n",
            "Epoch(0/1 : Batch number(43/782) : Batch loss : 0.7014033794403076\n",
            "Epoch(0/1 : Batch number(44/782) : Batch loss : 0.6241557002067566\n",
            "Epoch(0/1 : Batch number(45/782) : Batch loss : 0.5237515568733215\n",
            "Epoch(0/1 : Batch number(46/782) : Batch loss : 0.9765638113021851\n",
            "Epoch(0/1 : Batch number(47/782) : Batch loss : 0.6756967306137085\n",
            "Epoch(0/1 : Batch number(48/782) : Batch loss : 0.6704971790313721\n",
            "Epoch(0/1 : Batch number(49/782) : Batch loss : 0.9790474772453308\n",
            "Epoch(0/1 : Batch number(50/782) : Batch loss : 0.8087853789329529\n",
            "Epoch(0/1 : Batch number(51/782) : Batch loss : 0.848853588104248\n",
            "Epoch(0/1 : Batch number(52/782) : Batch loss : 0.8630632758140564\n",
            "Epoch(0/1 : Batch number(53/782) : Batch loss : 0.5881063342094421\n",
            "Epoch(0/1 : Batch number(54/782) : Batch loss : 0.8473202586174011\n",
            "Epoch(0/1 : Batch number(55/782) : Batch loss : 0.6837630867958069\n",
            "Epoch(0/1 : Batch number(56/782) : Batch loss : 0.9049112200737\n",
            "Epoch(0/1 : Batch number(57/782) : Batch loss : 0.8775328993797302\n",
            "Epoch(0/1 : Batch number(58/782) : Batch loss : 0.614031195640564\n",
            "Epoch(0/1 : Batch number(59/782) : Batch loss : 0.7076718211174011\n",
            "Epoch(0/1 : Batch number(60/782) : Batch loss : 0.7216026186943054\n",
            "Epoch(0/1 : Batch number(61/782) : Batch loss : 0.6787461638450623\n",
            "Epoch(0/1 : Batch number(62/782) : Batch loss : 0.558478593826294\n",
            "Epoch(0/1 : Batch number(63/782) : Batch loss : 0.7511516213417053\n",
            "Epoch(0/1 : Batch number(64/782) : Batch loss : 0.8758188486099243\n",
            "Epoch(0/1 : Batch number(65/782) : Batch loss : 0.7577309012413025\n",
            "Epoch(0/1 : Batch number(66/782) : Batch loss : 0.6921775341033936\n",
            "Epoch(0/1 : Batch number(67/782) : Batch loss : 0.8370751142501831\n",
            "Epoch(0/1 : Batch number(68/782) : Batch loss : 0.7002154588699341\n",
            "Epoch(0/1 : Batch number(69/782) : Batch loss : 0.874019980430603\n",
            "Epoch(0/1 : Batch number(70/782) : Batch loss : 0.6661927700042725\n",
            "Epoch(0/1 : Batch number(71/782) : Batch loss : 0.5763697028160095\n",
            "Epoch(0/1 : Batch number(72/782) : Batch loss : 0.67100590467453\n",
            "Epoch(0/1 : Batch number(73/782) : Batch loss : 1.108067512512207\n",
            "Epoch(0/1 : Batch number(74/782) : Batch loss : 0.7571204900741577\n",
            "Epoch(0/1 : Batch number(75/782) : Batch loss : 0.647695004940033\n",
            "Epoch(0/1 : Batch number(76/782) : Batch loss : 0.8503726124763489\n",
            "Epoch(0/1 : Batch number(77/782) : Batch loss : 0.7253697514533997\n",
            "Epoch(0/1 : Batch number(78/782) : Batch loss : 0.6905831694602966\n",
            "Epoch(0/1 : Batch number(79/782) : Batch loss : 0.4895937740802765\n",
            "Epoch(0/1 : Batch number(80/782) : Batch loss : 0.7883571982383728\n",
            "Epoch(0/1 : Batch number(81/782) : Batch loss : 0.6293365359306335\n",
            "Epoch(0/1 : Batch number(82/782) : Batch loss : 0.9455877542495728\n",
            "Epoch(0/1 : Batch number(83/782) : Batch loss : 0.749251663684845\n",
            "Epoch(0/1 : Batch number(84/782) : Batch loss : 0.7308434844017029\n",
            "Epoch(0/1 : Batch number(85/782) : Batch loss : 0.5202209949493408\n",
            "Epoch(0/1 : Batch number(86/782) : Batch loss : 0.7198275923728943\n",
            "Epoch(0/1 : Batch number(87/782) : Batch loss : 0.8359822630882263\n",
            "Epoch(0/1 : Batch number(88/782) : Batch loss : 0.51727694272995\n",
            "Epoch(0/1 : Batch number(89/782) : Batch loss : 0.6846510171890259\n",
            "Epoch(0/1 : Batch number(90/782) : Batch loss : 0.691383421421051\n",
            "Epoch(0/1 : Batch number(91/782) : Batch loss : 0.7230229377746582\n",
            "Epoch(0/1 : Batch number(92/782) : Batch loss : 0.7738018035888672\n",
            "Epoch(0/1 : Batch number(93/782) : Batch loss : 0.8929101824760437\n",
            "Epoch(0/1 : Batch number(94/782) : Batch loss : 0.682047963142395\n",
            "Epoch(0/1 : Batch number(95/782) : Batch loss : 0.7949301600456238\n",
            "Epoch(0/1 : Batch number(96/782) : Batch loss : 0.64446622133255\n",
            "Epoch(0/1 : Batch number(97/782) : Batch loss : 0.7720960378646851\n",
            "Epoch(0/1 : Batch number(98/782) : Batch loss : 0.8782364130020142\n",
            "Epoch(0/1 : Batch number(99/782) : Batch loss : 0.6255670189857483\n",
            "Epoch(0/1 : Batch number(100/782) : Batch loss : 0.985709547996521\n",
            "Epoch(0/1 : Batch number(101/782) : Batch loss : 0.9611371755599976\n",
            "Epoch(0/1 : Batch number(102/782) : Batch loss : 0.7117471694946289\n",
            "Epoch(0/1 : Batch number(103/782) : Batch loss : 0.7684639096260071\n",
            "Epoch(0/1 : Batch number(104/782) : Batch loss : 0.686688244342804\n",
            "Epoch(0/1 : Batch number(105/782) : Batch loss : 0.8793089389801025\n",
            "Epoch(0/1 : Batch number(106/782) : Batch loss : 0.8890050053596497\n",
            "Epoch(0/1 : Batch number(107/782) : Batch loss : 0.8827942609786987\n",
            "Epoch(0/1 : Batch number(108/782) : Batch loss : 0.8250259160995483\n",
            "Epoch(0/1 : Batch number(109/782) : Batch loss : 0.7068300247192383\n",
            "Epoch(0/1 : Batch number(110/782) : Batch loss : 0.7516966462135315\n",
            "Epoch(0/1 : Batch number(111/782) : Batch loss : 0.7172083258628845\n",
            "Epoch(0/1 : Batch number(112/782) : Batch loss : 0.746892511844635\n",
            "Epoch(0/1 : Batch number(113/782) : Batch loss : 0.6990318298339844\n",
            "Epoch(0/1 : Batch number(114/782) : Batch loss : 0.5746602416038513\n",
            "Epoch(0/1 : Batch number(115/782) : Batch loss : 0.8289031386375427\n",
            "Epoch(0/1 : Batch number(116/782) : Batch loss : 0.5652590990066528\n",
            "Epoch(0/1 : Batch number(117/782) : Batch loss : 0.5215414762496948\n",
            "Epoch(0/1 : Batch number(118/782) : Batch loss : 0.8312435746192932\n",
            "Epoch(0/1 : Batch number(119/782) : Batch loss : 0.5539265871047974\n",
            "Epoch(0/1 : Batch number(120/782) : Batch loss : 0.5764039754867554\n",
            "Epoch(0/1 : Batch number(121/782) : Batch loss : 0.6782500743865967\n",
            "Epoch(0/1 : Batch number(122/782) : Batch loss : 0.7330700159072876\n",
            "Epoch(0/1 : Batch number(123/782) : Batch loss : 0.9652597308158875\n",
            "Epoch(0/1 : Batch number(124/782) : Batch loss : 0.7345623970031738\n",
            "Epoch(0/1 : Batch number(125/782) : Batch loss : 0.711114227771759\n",
            "Epoch(0/1 : Batch number(126/782) : Batch loss : 0.7482332587242126\n",
            "Epoch(0/1 : Batch number(127/782) : Batch loss : 0.4852621555328369\n",
            "Epoch(0/1 : Batch number(128/782) : Batch loss : 0.6206033229827881\n",
            "Epoch(0/1 : Batch number(129/782) : Batch loss : 0.6613482236862183\n",
            "Epoch(0/1 : Batch number(130/782) : Batch loss : 0.690492570400238\n",
            "Epoch(0/1 : Batch number(131/782) : Batch loss : 0.7937355637550354\n",
            "Epoch(0/1 : Batch number(132/782) : Batch loss : 0.6775928139686584\n",
            "Epoch(0/1 : Batch number(133/782) : Batch loss : 0.6058725714683533\n",
            "Epoch(0/1 : Batch number(134/782) : Batch loss : 0.6660780906677246\n",
            "Epoch(0/1 : Batch number(135/782) : Batch loss : 0.7320247888565063\n",
            "Epoch(0/1 : Batch number(136/782) : Batch loss : 0.6604655385017395\n",
            "Epoch(0/1 : Batch number(137/782) : Batch loss : 0.5849648118019104\n",
            "Epoch(0/1 : Batch number(138/782) : Batch loss : 0.553205668926239\n",
            "Epoch(0/1 : Batch number(139/782) : Batch loss : 0.5216771960258484\n",
            "Epoch(0/1 : Batch number(140/782) : Batch loss : 0.9751873016357422\n",
            "Epoch(0/1 : Batch number(141/782) : Batch loss : 0.8289096355438232\n",
            "Epoch(0/1 : Batch number(142/782) : Batch loss : 0.6873364448547363\n",
            "Epoch(0/1 : Batch number(143/782) : Batch loss : 0.7482029795646667\n",
            "Epoch(0/1 : Batch number(144/782) : Batch loss : 0.8192869424819946\n",
            "Epoch(0/1 : Batch number(145/782) : Batch loss : 0.78428715467453\n",
            "Epoch(0/1 : Batch number(146/782) : Batch loss : 0.6118676066398621\n",
            "Epoch(0/1 : Batch number(147/782) : Batch loss : 0.8188821077346802\n",
            "Epoch(0/1 : Batch number(148/782) : Batch loss : 0.7255331873893738\n",
            "Epoch(0/1 : Batch number(149/782) : Batch loss : 0.7717369794845581\n",
            "Epoch(0/1 : Batch number(150/782) : Batch loss : 0.7048197388648987\n",
            "Epoch(0/1 : Batch number(151/782) : Batch loss : 0.6700658798217773\n",
            "Epoch(0/1 : Batch number(152/782) : Batch loss : 0.8938999772071838\n",
            "Epoch(0/1 : Batch number(153/782) : Batch loss : 0.6898072957992554\n",
            "Epoch(0/1 : Batch number(154/782) : Batch loss : 0.7264711856842041\n",
            "Epoch(0/1 : Batch number(155/782) : Batch loss : 0.9783753156661987\n",
            "Epoch(0/1 : Batch number(156/782) : Batch loss : 0.7409437894821167\n",
            "Epoch(0/1 : Batch number(157/782) : Batch loss : 0.8379154205322266\n",
            "Epoch(0/1 : Batch number(158/782) : Batch loss : 0.6172372698783875\n",
            "Epoch(0/1 : Batch number(159/782) : Batch loss : 0.7550027966499329\n",
            "Epoch(0/1 : Batch number(160/782) : Batch loss : 0.7326622605323792\n",
            "Epoch(0/1 : Batch number(161/782) : Batch loss : 0.6296408176422119\n",
            "Epoch(0/1 : Batch number(162/782) : Batch loss : 0.7629693150520325\n",
            "Epoch(0/1 : Batch number(163/782) : Batch loss : 0.625015139579773\n",
            "Epoch(0/1 : Batch number(164/782) : Batch loss : 0.6347691416740417\n",
            "Epoch(0/1 : Batch number(165/782) : Batch loss : 1.0546424388885498\n",
            "Epoch(0/1 : Batch number(166/782) : Batch loss : 0.7984219193458557\n",
            "Epoch(0/1 : Batch number(167/782) : Batch loss : 0.6834614276885986\n",
            "Epoch(0/1 : Batch number(168/782) : Batch loss : 0.7157493829727173\n",
            "Epoch(0/1 : Batch number(169/782) : Batch loss : 0.514915406703949\n",
            "Epoch(0/1 : Batch number(170/782) : Batch loss : 0.7050734162330627\n",
            "Epoch(0/1 : Batch number(171/782) : Batch loss : 0.4920852482318878\n",
            "Epoch(0/1 : Batch number(172/782) : Batch loss : 0.8412340879440308\n",
            "Epoch(0/1 : Batch number(173/782) : Batch loss : 0.9061535000801086\n",
            "Epoch(0/1 : Batch number(174/782) : Batch loss : 0.72394198179245\n",
            "Epoch(0/1 : Batch number(175/782) : Batch loss : 0.6760274171829224\n",
            "Epoch(0/1 : Batch number(176/782) : Batch loss : 0.4775093197822571\n",
            "Epoch(0/1 : Batch number(177/782) : Batch loss : 0.6540041565895081\n",
            "Epoch(0/1 : Batch number(178/782) : Batch loss : 0.5412679314613342\n",
            "Epoch(0/1 : Batch number(179/782) : Batch loss : 0.60047847032547\n",
            "Epoch(0/1 : Batch number(180/782) : Batch loss : 0.6982991099357605\n",
            "Epoch(0/1 : Batch number(181/782) : Batch loss : 0.7397065758705139\n",
            "Epoch(0/1 : Batch number(182/782) : Batch loss : 0.5837106704711914\n",
            "Epoch(0/1 : Batch number(183/782) : Batch loss : 0.8299030065536499\n",
            "Epoch(0/1 : Batch number(184/782) : Batch loss : 0.6999618411064148\n",
            "Epoch(0/1 : Batch number(185/782) : Batch loss : 0.5005972385406494\n",
            "Epoch(0/1 : Batch number(186/782) : Batch loss : 0.7215312719345093\n",
            "Epoch(0/1 : Batch number(187/782) : Batch loss : 0.7099493145942688\n",
            "Epoch(0/1 : Batch number(188/782) : Batch loss : 0.5413103103637695\n",
            "Epoch(0/1 : Batch number(189/782) : Batch loss : 0.554051399230957\n",
            "Epoch(0/1 : Batch number(190/782) : Batch loss : 0.4927414059638977\n",
            "Epoch(0/1 : Batch number(191/782) : Batch loss : 0.4901396334171295\n",
            "Epoch(0/1 : Batch number(192/782) : Batch loss : 0.6304994821548462\n",
            "Epoch(0/1 : Batch number(193/782) : Batch loss : 0.7800435423851013\n",
            "Epoch(0/1 : Batch number(194/782) : Batch loss : 0.6921354532241821\n",
            "Epoch(0/1 : Batch number(195/782) : Batch loss : 0.6047250032424927\n",
            "Epoch(0/1 : Batch number(196/782) : Batch loss : 0.7055231332778931\n",
            "Epoch(0/1 : Batch number(197/782) : Batch loss : 0.600055456161499\n",
            "Epoch(0/1 : Batch number(198/782) : Batch loss : 0.6530872583389282\n",
            "Epoch(0/1 : Batch number(199/782) : Batch loss : 0.6900283098220825\n",
            "Epoch(0/1 : Batch number(200/782) : Batch loss : 0.6096674799919128\n",
            "Epoch(0/1 : Batch number(201/782) : Batch loss : 0.8769314289093018\n",
            "Epoch(0/1 : Batch number(202/782) : Batch loss : 0.5464056730270386\n",
            "Epoch(0/1 : Batch number(203/782) : Batch loss : 0.6313361525535583\n",
            "Epoch(0/1 : Batch number(204/782) : Batch loss : 0.559828519821167\n",
            "Epoch(0/1 : Batch number(205/782) : Batch loss : 0.9731305241584778\n",
            "Epoch(0/1 : Batch number(206/782) : Batch loss : 0.866950511932373\n",
            "Epoch(0/1 : Batch number(207/782) : Batch loss : 0.6404479742050171\n",
            "Epoch(0/1 : Batch number(208/782) : Batch loss : 0.5837936997413635\n",
            "Epoch(0/1 : Batch number(209/782) : Batch loss : 0.5817552804946899\n",
            "Epoch(0/1 : Batch number(210/782) : Batch loss : 0.746487021446228\n",
            "Epoch(0/1 : Batch number(211/782) : Batch loss : 0.6794417500495911\n",
            "Epoch(0/1 : Batch number(212/782) : Batch loss : 0.5808848738670349\n",
            "Epoch(0/1 : Batch number(213/782) : Batch loss : 0.6602047681808472\n",
            "Epoch(0/1 : Batch number(214/782) : Batch loss : 0.8164374828338623\n",
            "Epoch(0/1 : Batch number(215/782) : Batch loss : 0.9214011430740356\n",
            "Epoch(0/1 : Batch number(216/782) : Batch loss : 0.5569775700569153\n",
            "Epoch(0/1 : Batch number(217/782) : Batch loss : 0.7148340344429016\n",
            "Epoch(0/1 : Batch number(218/782) : Batch loss : 0.8791320323944092\n",
            "Epoch(0/1 : Batch number(219/782) : Batch loss : 0.8516681790351868\n",
            "Epoch(0/1 : Batch number(220/782) : Batch loss : 0.7539125680923462\n",
            "Epoch(0/1 : Batch number(221/782) : Batch loss : 0.6571748852729797\n",
            "Epoch(0/1 : Batch number(222/782) : Batch loss : 0.7179529666900635\n",
            "Epoch(0/1 : Batch number(223/782) : Batch loss : 0.7871347069740295\n",
            "Epoch(0/1 : Batch number(224/782) : Batch loss : 0.8163805603981018\n",
            "Epoch(0/1 : Batch number(225/782) : Batch loss : 0.8262112140655518\n",
            "Epoch(0/1 : Batch number(226/782) : Batch loss : 0.8493897318840027\n",
            "Epoch(0/1 : Batch number(227/782) : Batch loss : 0.5925738215446472\n",
            "Epoch(0/1 : Batch number(228/782) : Batch loss : 0.7410290241241455\n",
            "Epoch(0/1 : Batch number(229/782) : Batch loss : 0.6335362792015076\n",
            "Epoch(0/1 : Batch number(230/782) : Batch loss : 0.6736552715301514\n",
            "Epoch(0/1 : Batch number(231/782) : Batch loss : 0.7451667189598083\n",
            "Epoch(0/1 : Batch number(232/782) : Batch loss : 0.6465782523155212\n",
            "Epoch(0/1 : Batch number(233/782) : Batch loss : 0.6141890287399292\n",
            "Epoch(0/1 : Batch number(234/782) : Batch loss : 0.6326389908790588\n",
            "Epoch(0/1 : Batch number(235/782) : Batch loss : 0.9055097103118896\n",
            "Epoch(0/1 : Batch number(236/782) : Batch loss : 0.684596061706543\n",
            "Epoch(0/1 : Batch number(237/782) : Batch loss : 0.5966526865959167\n",
            "Epoch(0/1 : Batch number(238/782) : Batch loss : 0.5598820447921753\n",
            "Epoch(0/1 : Batch number(239/782) : Batch loss : 0.6454652547836304\n",
            "Epoch(0/1 : Batch number(240/782) : Batch loss : 0.7550150752067566\n",
            "Epoch(0/1 : Batch number(241/782) : Batch loss : 0.7784075736999512\n",
            "Epoch(0/1 : Batch number(242/782) : Batch loss : 0.5524711012840271\n",
            "Epoch(0/1 : Batch number(243/782) : Batch loss : 0.4821746051311493\n",
            "Epoch(0/1 : Batch number(244/782) : Batch loss : 0.7074422836303711\n",
            "Epoch(0/1 : Batch number(245/782) : Batch loss : 0.747679591178894\n",
            "Epoch(0/1 : Batch number(246/782) : Batch loss : 0.6057080030441284\n",
            "Epoch(0/1 : Batch number(247/782) : Batch loss : 0.7529542446136475\n",
            "Epoch(0/1 : Batch number(248/782) : Batch loss : 0.7794824242591858\n",
            "Epoch(0/1 : Batch number(249/782) : Batch loss : 0.5803632736206055\n",
            "Epoch(0/1 : Batch number(250/782) : Batch loss : 0.8242791295051575\n",
            "Epoch(0/1 : Batch number(251/782) : Batch loss : 0.6255201697349548\n",
            "Epoch(0/1 : Batch number(252/782) : Batch loss : 0.7042071223258972\n",
            "Epoch(0/1 : Batch number(253/782) : Batch loss : 0.7138561606407166\n",
            "Epoch(0/1 : Batch number(254/782) : Batch loss : 0.8241796493530273\n",
            "Epoch(0/1 : Batch number(255/782) : Batch loss : 0.6770963072776794\n",
            "Epoch(0/1 : Batch number(256/782) : Batch loss : 0.8030239939689636\n",
            "Epoch(0/1 : Batch number(257/782) : Batch loss : 0.7071150541305542\n",
            "Epoch(0/1 : Batch number(258/782) : Batch loss : 1.087227463722229\n",
            "Epoch(0/1 : Batch number(259/782) : Batch loss : 0.8032351732254028\n",
            "Epoch(0/1 : Batch number(260/782) : Batch loss : 0.7483094334602356\n",
            "Epoch(0/1 : Batch number(261/782) : Batch loss : 0.7573463916778564\n",
            "Epoch(0/1 : Batch number(262/782) : Batch loss : 0.6603549718856812\n",
            "Epoch(0/1 : Batch number(263/782) : Batch loss : 0.7924014925956726\n",
            "Epoch(0/1 : Batch number(264/782) : Batch loss : 0.7208594083786011\n",
            "Epoch(0/1 : Batch number(265/782) : Batch loss : 0.5443861484527588\n",
            "Epoch(0/1 : Batch number(266/782) : Batch loss : 0.910405158996582\n",
            "Epoch(0/1 : Batch number(267/782) : Batch loss : 0.5206331610679626\n",
            "Epoch(0/1 : Batch number(268/782) : Batch loss : 0.705623209476471\n",
            "Epoch(0/1 : Batch number(269/782) : Batch loss : 0.761421263217926\n",
            "Epoch(0/1 : Batch number(270/782) : Batch loss : 0.6060038208961487\n",
            "Epoch(0/1 : Batch number(271/782) : Batch loss : 0.5916809439659119\n",
            "Epoch(0/1 : Batch number(272/782) : Batch loss : 0.5295214056968689\n",
            "Epoch(0/1 : Batch number(273/782) : Batch loss : 0.9644303917884827\n",
            "Epoch(0/1 : Batch number(274/782) : Batch loss : 0.6776453256607056\n",
            "Epoch(0/1 : Batch number(275/782) : Batch loss : 0.561725378036499\n",
            "Epoch(0/1 : Batch number(276/782) : Batch loss : 0.7093044519424438\n",
            "Epoch(0/1 : Batch number(277/782) : Batch loss : 0.7964497804641724\n",
            "Epoch(0/1 : Batch number(278/782) : Batch loss : 0.6340951323509216\n",
            "Epoch(0/1 : Batch number(279/782) : Batch loss : 1.1384419202804565\n",
            "Epoch(0/1 : Batch number(280/782) : Batch loss : 0.5638978481292725\n",
            "Epoch(0/1 : Batch number(281/782) : Batch loss : 0.5175246596336365\n",
            "Epoch(0/1 : Batch number(282/782) : Batch loss : 0.6271566152572632\n",
            "Epoch(0/1 : Batch number(283/782) : Batch loss : 0.6856960654258728\n",
            "Epoch(0/1 : Batch number(284/782) : Batch loss : 0.7489723563194275\n",
            "Epoch(0/1 : Batch number(285/782) : Batch loss : 0.46487754583358765\n",
            "Epoch(0/1 : Batch number(286/782) : Batch loss : 0.4712206721305847\n",
            "Epoch(0/1 : Batch number(287/782) : Batch loss : 0.6733197569847107\n",
            "Epoch(0/1 : Batch number(288/782) : Batch loss : 0.8304205536842346\n",
            "Epoch(0/1 : Batch number(289/782) : Batch loss : 0.7549710273742676\n",
            "Epoch(0/1 : Batch number(290/782) : Batch loss : 0.5475859045982361\n",
            "Epoch(0/1 : Batch number(291/782) : Batch loss : 0.8835991024971008\n",
            "Epoch(0/1 : Batch number(292/782) : Batch loss : 0.7725538015365601\n",
            "Epoch(0/1 : Batch number(293/782) : Batch loss : 0.7831164002418518\n",
            "Epoch(0/1 : Batch number(294/782) : Batch loss : 0.5349560976028442\n",
            "Epoch(0/1 : Batch number(295/782) : Batch loss : 0.8291770815849304\n",
            "Epoch(0/1 : Batch number(296/782) : Batch loss : 0.8219281435012817\n",
            "Epoch(0/1 : Batch number(297/782) : Batch loss : 0.48560288548469543\n",
            "Epoch(0/1 : Batch number(298/782) : Batch loss : 0.7560515403747559\n",
            "Epoch(0/1 : Batch number(299/782) : Batch loss : 1.0393028259277344\n",
            "Epoch(0/1 : Batch number(300/782) : Batch loss : 0.5671577453613281\n",
            "Epoch(0/1 : Batch number(301/782) : Batch loss : 0.5837841033935547\n",
            "Epoch(0/1 : Batch number(302/782) : Batch loss : 0.5184619426727295\n",
            "Epoch(0/1 : Batch number(303/782) : Batch loss : 0.8042944669723511\n",
            "Epoch(0/1 : Batch number(304/782) : Batch loss : 0.6818181872367859\n",
            "Epoch(0/1 : Batch number(305/782) : Batch loss : 0.7965936660766602\n",
            "Epoch(0/1 : Batch number(306/782) : Batch loss : 0.6304868459701538\n",
            "Epoch(0/1 : Batch number(307/782) : Batch loss : 0.5889286994934082\n",
            "Epoch(0/1 : Batch number(308/782) : Batch loss : 0.7207698225975037\n",
            "Epoch(0/1 : Batch number(309/782) : Batch loss : 0.5167861580848694\n",
            "Epoch(0/1 : Batch number(310/782) : Batch loss : 0.6947059035301208\n",
            "Epoch(0/1 : Batch number(311/782) : Batch loss : 0.7595972418785095\n",
            "Epoch(0/1 : Batch number(312/782) : Batch loss : 0.7442110776901245\n",
            "Epoch(0/1 : Batch number(313/782) : Batch loss : 0.5600998401641846\n",
            "Epoch(0/1 : Batch number(314/782) : Batch loss : 0.6835666298866272\n",
            "Epoch(0/1 : Batch number(315/782) : Batch loss : 0.7001528739929199\n",
            "Epoch(0/1 : Batch number(316/782) : Batch loss : 0.9481755495071411\n",
            "Epoch(0/1 : Batch number(317/782) : Batch loss : 0.8302580118179321\n",
            "Epoch(0/1 : Batch number(318/782) : Batch loss : 0.8327852487564087\n",
            "Epoch(0/1 : Batch number(319/782) : Batch loss : 0.636206328868866\n",
            "Epoch(0/1 : Batch number(320/782) : Batch loss : 0.6232505440711975\n",
            "Epoch(0/1 : Batch number(321/782) : Batch loss : 0.5699736475944519\n",
            "Epoch(0/1 : Batch number(322/782) : Batch loss : 0.6226217746734619\n",
            "Epoch(0/1 : Batch number(323/782) : Batch loss : 0.8502669334411621\n",
            "Epoch(0/1 : Batch number(324/782) : Batch loss : 0.5275945663452148\n",
            "Epoch(0/1 : Batch number(325/782) : Batch loss : 0.6084798574447632\n",
            "Epoch(0/1 : Batch number(326/782) : Batch loss : 0.8059203624725342\n",
            "Epoch(0/1 : Batch number(327/782) : Batch loss : 0.5527462363243103\n",
            "Epoch(0/1 : Batch number(328/782) : Batch loss : 0.5864450931549072\n",
            "Epoch(0/1 : Batch number(329/782) : Batch loss : 0.7866865992546082\n",
            "Epoch(0/1 : Batch number(330/782) : Batch loss : 1.0853643417358398\n",
            "Epoch(0/1 : Batch number(331/782) : Batch loss : 1.0265986919403076\n",
            "Epoch(0/1 : Batch number(332/782) : Batch loss : 0.8609610795974731\n",
            "Epoch(0/1 : Batch number(333/782) : Batch loss : 0.519181489944458\n",
            "Epoch(0/1 : Batch number(334/782) : Batch loss : 0.8375372290611267\n",
            "Epoch(0/1 : Batch number(335/782) : Batch loss : 0.7001850605010986\n",
            "Epoch(0/1 : Batch number(336/782) : Batch loss : 0.6579512357711792\n",
            "Epoch(0/1 : Batch number(337/782) : Batch loss : 0.528994619846344\n",
            "Epoch(0/1 : Batch number(338/782) : Batch loss : 0.8400698900222778\n",
            "Epoch(0/1 : Batch number(339/782) : Batch loss : 0.6337690353393555\n",
            "Epoch(0/1 : Batch number(340/782) : Batch loss : 0.6907905340194702\n",
            "Epoch(0/1 : Batch number(341/782) : Batch loss : 0.8666461706161499\n",
            "Epoch(0/1 : Batch number(342/782) : Batch loss : 0.8113015294075012\n",
            "Epoch(0/1 : Batch number(343/782) : Batch loss : 0.8327746391296387\n",
            "Epoch(0/1 : Batch number(344/782) : Batch loss : 0.4502112865447998\n",
            "Epoch(0/1 : Batch number(345/782) : Batch loss : 0.8030344247817993\n",
            "Epoch(0/1 : Batch number(346/782) : Batch loss : 0.5878751873970032\n",
            "Epoch(0/1 : Batch number(347/782) : Batch loss : 0.819952130317688\n",
            "Epoch(0/1 : Batch number(348/782) : Batch loss : 0.761486828327179\n",
            "Epoch(0/1 : Batch number(349/782) : Batch loss : 0.9431379437446594\n",
            "Epoch(0/1 : Batch number(350/782) : Batch loss : 0.4507704973220825\n",
            "Epoch(0/1 : Batch number(351/782) : Batch loss : 0.8715470433235168\n",
            "Epoch(0/1 : Batch number(352/782) : Batch loss : 0.7534298896789551\n",
            "Epoch(0/1 : Batch number(353/782) : Batch loss : 0.6171391010284424\n",
            "Epoch(0/1 : Batch number(354/782) : Batch loss : 0.8108788728713989\n",
            "Epoch(0/1 : Batch number(355/782) : Batch loss : 0.4840673804283142\n",
            "Epoch(0/1 : Batch number(356/782) : Batch loss : 0.5445681810379028\n",
            "Epoch(0/1 : Batch number(357/782) : Batch loss : 0.8357635736465454\n",
            "Epoch(0/1 : Batch number(358/782) : Batch loss : 0.664442241191864\n",
            "Epoch(0/1 : Batch number(359/782) : Batch loss : 0.6091429591178894\n",
            "Epoch(0/1 : Batch number(360/782) : Batch loss : 0.6955860257148743\n",
            "Epoch(0/1 : Batch number(361/782) : Batch loss : 1.0859813690185547\n",
            "Epoch(0/1 : Batch number(362/782) : Batch loss : 0.7233143448829651\n",
            "Epoch(0/1 : Batch number(363/782) : Batch loss : 0.5900653600692749\n",
            "Epoch(0/1 : Batch number(364/782) : Batch loss : 0.6974246501922607\n",
            "Epoch(0/1 : Batch number(365/782) : Batch loss : 0.8963025808334351\n",
            "Epoch(0/1 : Batch number(366/782) : Batch loss : 0.665943443775177\n",
            "Epoch(0/1 : Batch number(367/782) : Batch loss : 0.696723222732544\n",
            "Epoch(0/1 : Batch number(368/782) : Batch loss : 0.5550776124000549\n",
            "Epoch(0/1 : Batch number(369/782) : Batch loss : 0.630403995513916\n",
            "Epoch(0/1 : Batch number(370/782) : Batch loss : 0.635936439037323\n",
            "Epoch(0/1 : Batch number(371/782) : Batch loss : 0.9182476997375488\n",
            "Epoch(0/1 : Batch number(372/782) : Batch loss : 0.5796287059783936\n",
            "Epoch(0/1 : Batch number(373/782) : Batch loss : 0.6502423286437988\n",
            "Epoch(0/1 : Batch number(374/782) : Batch loss : 0.7005269527435303\n",
            "Epoch(0/1 : Batch number(375/782) : Batch loss : 0.8826208710670471\n",
            "Epoch(0/1 : Batch number(376/782) : Batch loss : 0.7568421959877014\n",
            "Epoch(0/1 : Batch number(377/782) : Batch loss : 0.6754599213600159\n",
            "Epoch(0/1 : Batch number(378/782) : Batch loss : 0.6461901664733887\n",
            "Epoch(0/1 : Batch number(379/782) : Batch loss : 0.6794132590293884\n",
            "Epoch(0/1 : Batch number(380/782) : Batch loss : 0.6686785817146301\n",
            "Epoch(0/1 : Batch number(381/782) : Batch loss : 0.8160897493362427\n",
            "Epoch(0/1 : Batch number(382/782) : Batch loss : 0.49792346358299255\n",
            "Epoch(0/1 : Batch number(383/782) : Batch loss : 0.9263265132904053\n",
            "Epoch(0/1 : Batch number(384/782) : Batch loss : 0.7160813808441162\n",
            "Epoch(0/1 : Batch number(385/782) : Batch loss : 0.6736226677894592\n",
            "Epoch(0/1 : Batch number(386/782) : Batch loss : 0.6004400253295898\n",
            "Epoch(0/1 : Batch number(387/782) : Batch loss : 0.5353379249572754\n",
            "Epoch(0/1 : Batch number(388/782) : Batch loss : 0.5303202867507935\n",
            "Epoch(0/1 : Batch number(389/782) : Batch loss : 0.4838913083076477\n",
            "Epoch(0/1 : Batch number(390/782) : Batch loss : 0.5755405426025391\n",
            "Epoch(0/1 : Batch number(391/782) : Batch loss : 0.6700915694236755\n",
            "Epoch(0/1 : Batch number(392/782) : Batch loss : 0.526240885257721\n",
            "Epoch(0/1 : Batch number(393/782) : Batch loss : 0.46309348940849304\n",
            "Epoch(0/1 : Batch number(394/782) : Batch loss : 0.6221078634262085\n",
            "Epoch(0/1 : Batch number(395/782) : Batch loss : 0.5171442031860352\n",
            "Epoch(0/1 : Batch number(396/782) : Batch loss : 1.0300508737564087\n",
            "Epoch(0/1 : Batch number(397/782) : Batch loss : 0.5371657013893127\n",
            "Epoch(0/1 : Batch number(398/782) : Batch loss : 0.490981787443161\n",
            "Epoch(0/1 : Batch number(399/782) : Batch loss : 0.6486814618110657\n",
            "Epoch(0/1 : Batch number(400/782) : Batch loss : 0.82540363073349\n",
            "Epoch(0/1 : Batch number(401/782) : Batch loss : 0.6956547498703003\n",
            "Epoch(0/1 : Batch number(402/782) : Batch loss : 0.9036520719528198\n",
            "Epoch(0/1 : Batch number(403/782) : Batch loss : 0.8342573046684265\n",
            "Epoch(0/1 : Batch number(404/782) : Batch loss : 0.49258431792259216\n",
            "Epoch(0/1 : Batch number(405/782) : Batch loss : 0.6494064331054688\n",
            "Epoch(0/1 : Batch number(406/782) : Batch loss : 0.9617691040039062\n",
            "Epoch(0/1 : Batch number(407/782) : Batch loss : 0.735796332359314\n",
            "Epoch(0/1 : Batch number(408/782) : Batch loss : 0.7782663106918335\n",
            "Epoch(0/1 : Batch number(409/782) : Batch loss : 0.478397011756897\n",
            "Epoch(0/1 : Batch number(410/782) : Batch loss : 0.709639310836792\n",
            "Epoch(0/1 : Batch number(411/782) : Batch loss : 0.7208951711654663\n",
            "Epoch(0/1 : Batch number(412/782) : Batch loss : 0.4703367352485657\n",
            "Epoch(0/1 : Batch number(413/782) : Batch loss : 0.486670583486557\n",
            "Epoch(0/1 : Batch number(414/782) : Batch loss : 0.5228503942489624\n",
            "Epoch(0/1 : Batch number(415/782) : Batch loss : 0.8897603154182434\n",
            "Epoch(0/1 : Batch number(416/782) : Batch loss : 0.4984265863895416\n",
            "Epoch(0/1 : Batch number(417/782) : Batch loss : 0.6276836395263672\n",
            "Epoch(0/1 : Batch number(418/782) : Batch loss : 0.5752193331718445\n",
            "Epoch(0/1 : Batch number(419/782) : Batch loss : 0.8863341212272644\n",
            "Epoch(0/1 : Batch number(420/782) : Batch loss : 0.8117809295654297\n",
            "Epoch(0/1 : Batch number(421/782) : Batch loss : 0.5869487524032593\n",
            "Epoch(0/1 : Batch number(422/782) : Batch loss : 0.6501308679580688\n",
            "Epoch(0/1 : Batch number(423/782) : Batch loss : 0.6941796541213989\n",
            "Epoch(0/1 : Batch number(424/782) : Batch loss : 0.7538275122642517\n",
            "Epoch(0/1 : Batch number(425/782) : Batch loss : 0.6270586252212524\n",
            "Epoch(0/1 : Batch number(426/782) : Batch loss : 0.6501830816268921\n",
            "Epoch(0/1 : Batch number(427/782) : Batch loss : 0.6296014785766602\n",
            "Epoch(0/1 : Batch number(428/782) : Batch loss : 0.743066132068634\n",
            "Epoch(0/1 : Batch number(429/782) : Batch loss : 0.6405611634254456\n",
            "Epoch(0/1 : Batch number(430/782) : Batch loss : 0.5819898247718811\n",
            "Epoch(0/1 : Batch number(431/782) : Batch loss : 0.7797905206680298\n",
            "Epoch(0/1 : Batch number(432/782) : Batch loss : 0.8965776562690735\n",
            "Epoch(0/1 : Batch number(433/782) : Batch loss : 0.6002196669578552\n",
            "Epoch(0/1 : Batch number(434/782) : Batch loss : 0.48724740743637085\n",
            "Epoch(0/1 : Batch number(435/782) : Batch loss : 0.5880470275878906\n",
            "Epoch(0/1 : Batch number(436/782) : Batch loss : 1.0444815158843994\n",
            "Epoch(0/1 : Batch number(437/782) : Batch loss : 0.6150146126747131\n",
            "Epoch(0/1 : Batch number(438/782) : Batch loss : 0.820017397403717\n",
            "Epoch(0/1 : Batch number(439/782) : Batch loss : 0.7894290089607239\n",
            "Epoch(0/1 : Batch number(440/782) : Batch loss : 0.7241268157958984\n",
            "Epoch(0/1 : Batch number(441/782) : Batch loss : 0.6588950753211975\n",
            "Epoch(0/1 : Batch number(442/782) : Batch loss : 0.6973790526390076\n",
            "Epoch(0/1 : Batch number(443/782) : Batch loss : 0.9314663410186768\n",
            "Epoch(0/1 : Batch number(444/782) : Batch loss : 0.6226584911346436\n",
            "Epoch(0/1 : Batch number(445/782) : Batch loss : 0.5392823219299316\n",
            "Epoch(0/1 : Batch number(446/782) : Batch loss : 0.6497384309768677\n",
            "Epoch(0/1 : Batch number(447/782) : Batch loss : 0.9346825480461121\n",
            "Epoch(0/1 : Batch number(448/782) : Batch loss : 0.4516327977180481\n",
            "Epoch(0/1 : Batch number(449/782) : Batch loss : 0.6563332080841064\n",
            "Epoch(0/1 : Batch number(450/782) : Batch loss : 0.7405692338943481\n",
            "Epoch(0/1 : Batch number(451/782) : Batch loss : 0.5449671745300293\n",
            "Epoch(0/1 : Batch number(452/782) : Batch loss : 0.49802783131599426\n",
            "Epoch(0/1 : Batch number(453/782) : Batch loss : 0.5594144463539124\n",
            "Epoch(0/1 : Batch number(454/782) : Batch loss : 0.5876039862632751\n",
            "Epoch(0/1 : Batch number(455/782) : Batch loss : 0.6001585721969604\n",
            "Epoch(0/1 : Batch number(456/782) : Batch loss : 0.5585918426513672\n",
            "Epoch(0/1 : Batch number(457/782) : Batch loss : 0.6184465289115906\n",
            "Epoch(0/1 : Batch number(458/782) : Batch loss : 0.7637414932250977\n",
            "Epoch(0/1 : Batch number(459/782) : Batch loss : 0.8151899576187134\n",
            "Epoch(0/1 : Batch number(460/782) : Batch loss : 0.6045629382133484\n",
            "Epoch(0/1 : Batch number(461/782) : Batch loss : 0.6059987545013428\n",
            "Epoch(0/1 : Batch number(462/782) : Batch loss : 0.8140208125114441\n",
            "Epoch(0/1 : Batch number(463/782) : Batch loss : 0.7301580905914307\n",
            "Epoch(0/1 : Batch number(464/782) : Batch loss : 0.8972651958465576\n",
            "Epoch(0/1 : Batch number(465/782) : Batch loss : 0.45076146721839905\n",
            "Epoch(0/1 : Batch number(466/782) : Batch loss : 0.5071413516998291\n",
            "Epoch(0/1 : Batch number(467/782) : Batch loss : 0.5158958435058594\n",
            "Epoch(0/1 : Batch number(468/782) : Batch loss : 0.773151159286499\n",
            "Epoch(0/1 : Batch number(469/782) : Batch loss : 0.7946814894676208\n",
            "Epoch(0/1 : Batch number(470/782) : Batch loss : 0.9350125789642334\n",
            "Epoch(0/1 : Batch number(471/782) : Batch loss : 0.7102633714675903\n",
            "Epoch(0/1 : Batch number(472/782) : Batch loss : 0.5757837891578674\n",
            "Epoch(0/1 : Batch number(473/782) : Batch loss : 0.6106745600700378\n",
            "Epoch(0/1 : Batch number(474/782) : Batch loss : 0.5417292714118958\n",
            "Epoch(0/1 : Batch number(475/782) : Batch loss : 0.6511551737785339\n",
            "Epoch(0/1 : Batch number(476/782) : Batch loss : 0.6430988311767578\n",
            "Epoch(0/1 : Batch number(477/782) : Batch loss : 0.7968973517417908\n",
            "Epoch(0/1 : Batch number(478/782) : Batch loss : 0.8508052229881287\n",
            "Epoch(0/1 : Batch number(479/782) : Batch loss : 0.5422179102897644\n",
            "Epoch(0/1 : Batch number(480/782) : Batch loss : 0.7322967052459717\n",
            "Epoch(0/1 : Batch number(481/782) : Batch loss : 0.9713183641433716\n",
            "Epoch(0/1 : Batch number(482/782) : Batch loss : 0.7038814425468445\n",
            "Epoch(0/1 : Batch number(483/782) : Batch loss : 0.8217843174934387\n",
            "Epoch(0/1 : Batch number(484/782) : Batch loss : 0.5999342203140259\n",
            "Epoch(0/1 : Batch number(485/782) : Batch loss : 0.45587143301963806\n",
            "Epoch(0/1 : Batch number(486/782) : Batch loss : 0.869897723197937\n",
            "Epoch(0/1 : Batch number(487/782) : Batch loss : 0.8851907253265381\n",
            "Epoch(0/1 : Batch number(488/782) : Batch loss : 0.8954483270645142\n",
            "Epoch(0/1 : Batch number(489/782) : Batch loss : 0.6979653835296631\n",
            "Epoch(0/1 : Batch number(490/782) : Batch loss : 0.7455567121505737\n",
            "Epoch(0/1 : Batch number(491/782) : Batch loss : 0.7606235146522522\n",
            "Epoch(0/1 : Batch number(492/782) : Batch loss : 0.5902086496353149\n",
            "Epoch(0/1 : Batch number(493/782) : Batch loss : 0.4524475932121277\n",
            "Epoch(0/1 : Batch number(494/782) : Batch loss : 0.6508873701095581\n",
            "Epoch(0/1 : Batch number(495/782) : Batch loss : 0.7775726318359375\n",
            "Epoch(0/1 : Batch number(496/782) : Batch loss : 0.8919022083282471\n",
            "Epoch(0/1 : Batch number(497/782) : Batch loss : 0.8859373331069946\n",
            "Epoch(0/1 : Batch number(498/782) : Batch loss : 0.6400318145751953\n",
            "Epoch(0/1 : Batch number(499/782) : Batch loss : 0.743510901927948\n",
            "Epoch(0/1 : Batch number(500/782) : Batch loss : 0.4261515736579895\n",
            "Epoch(0/1 : Batch number(501/782) : Batch loss : 0.5936350226402283\n",
            "Epoch(0/1 : Batch number(502/782) : Batch loss : 0.7020977735519409\n",
            "Epoch(0/1 : Batch number(503/782) : Batch loss : 0.5045114159584045\n",
            "Epoch(0/1 : Batch number(504/782) : Batch loss : 0.6030476093292236\n",
            "Epoch(0/1 : Batch number(505/782) : Batch loss : 0.5972234010696411\n",
            "Epoch(0/1 : Batch number(506/782) : Batch loss : 0.5752241611480713\n",
            "Epoch(0/1 : Batch number(507/782) : Batch loss : 0.7667431831359863\n",
            "Epoch(0/1 : Batch number(508/782) : Batch loss : 0.7532473206520081\n",
            "Epoch(0/1 : Batch number(509/782) : Batch loss : 0.4895683526992798\n",
            "Epoch(0/1 : Batch number(510/782) : Batch loss : 0.6554645299911499\n",
            "Epoch(0/1 : Batch number(511/782) : Batch loss : 0.6705630421638489\n",
            "Epoch(0/1 : Batch number(512/782) : Batch loss : 0.5187370777130127\n",
            "Epoch(0/1 : Batch number(513/782) : Batch loss : 0.7548816204071045\n",
            "Epoch(0/1 : Batch number(514/782) : Batch loss : 0.6675657629966736\n",
            "Epoch(0/1 : Batch number(515/782) : Batch loss : 0.9384232759475708\n",
            "Epoch(0/1 : Batch number(516/782) : Batch loss : 0.7214913964271545\n",
            "Epoch(0/1 : Batch number(517/782) : Batch loss : 0.7234647870063782\n",
            "Epoch(0/1 : Batch number(518/782) : Batch loss : 0.6136986613273621\n",
            "Epoch(0/1 : Batch number(519/782) : Batch loss : 0.6432673931121826\n",
            "Epoch(0/1 : Batch number(520/782) : Batch loss : 0.6319423913955688\n",
            "Epoch(0/1 : Batch number(521/782) : Batch loss : 0.7634716033935547\n",
            "Epoch(0/1 : Batch number(522/782) : Batch loss : 0.5327962636947632\n",
            "Epoch(0/1 : Batch number(523/782) : Batch loss : 0.8298534750938416\n",
            "Epoch(0/1 : Batch number(524/782) : Batch loss : 0.6249352097511292\n",
            "Epoch(0/1 : Batch number(525/782) : Batch loss : 0.8694204092025757\n",
            "Epoch(0/1 : Batch number(526/782) : Batch loss : 0.5533586740493774\n",
            "Epoch(0/1 : Batch number(527/782) : Batch loss : 0.8393341302871704\n",
            "Epoch(0/1 : Batch number(528/782) : Batch loss : 0.6294375061988831\n",
            "Epoch(0/1 : Batch number(529/782) : Batch loss : 0.6399840712547302\n",
            "Epoch(0/1 : Batch number(530/782) : Batch loss : 0.4285050630569458\n",
            "Epoch(0/1 : Batch number(531/782) : Batch loss : 0.6031586527824402\n",
            "Epoch(0/1 : Batch number(532/782) : Batch loss : 0.5053779482841492\n",
            "Epoch(0/1 : Batch number(533/782) : Batch loss : 0.8901936411857605\n",
            "Epoch(0/1 : Batch number(534/782) : Batch loss : 0.45448005199432373\n",
            "Epoch(0/1 : Batch number(535/782) : Batch loss : 0.7240571975708008\n",
            "Epoch(0/1 : Batch number(536/782) : Batch loss : 0.8069934844970703\n",
            "Epoch(0/1 : Batch number(537/782) : Batch loss : 0.6464405059814453\n",
            "Epoch(0/1 : Batch number(538/782) : Batch loss : 0.49751096963882446\n",
            "Epoch(0/1 : Batch number(539/782) : Batch loss : 0.5821792483329773\n",
            "Epoch(0/1 : Batch number(540/782) : Batch loss : 0.6301093697547913\n",
            "Epoch(0/1 : Batch number(541/782) : Batch loss : 0.6383035182952881\n",
            "Epoch(0/1 : Batch number(542/782) : Batch loss : 0.6536915302276611\n",
            "Epoch(0/1 : Batch number(543/782) : Batch loss : 0.5190029740333557\n",
            "Epoch(0/1 : Batch number(544/782) : Batch loss : 0.9626753330230713\n",
            "Epoch(0/1 : Batch number(545/782) : Batch loss : 1.1117881536483765\n",
            "Epoch(0/1 : Batch number(546/782) : Batch loss : 0.7508246302604675\n",
            "Epoch(0/1 : Batch number(547/782) : Batch loss : 0.797614574432373\n",
            "Epoch(0/1 : Batch number(548/782) : Batch loss : 0.5684730410575867\n",
            "Epoch(0/1 : Batch number(549/782) : Batch loss : 0.48757272958755493\n",
            "Epoch(0/1 : Batch number(550/782) : Batch loss : 0.4634162485599518\n",
            "Epoch(0/1 : Batch number(551/782) : Batch loss : 0.7309874296188354\n",
            "Epoch(0/1 : Batch number(552/782) : Batch loss : 0.6863749027252197\n",
            "Epoch(0/1 : Batch number(553/782) : Batch loss : 0.43529823422431946\n",
            "Epoch(0/1 : Batch number(554/782) : Batch loss : 0.4737819731235504\n",
            "Epoch(0/1 : Batch number(555/782) : Batch loss : 0.6933456063270569\n",
            "Epoch(0/1 : Batch number(556/782) : Batch loss : 0.5259338021278381\n",
            "Epoch(0/1 : Batch number(557/782) : Batch loss : 0.6776214241981506\n",
            "Epoch(0/1 : Batch number(558/782) : Batch loss : 0.4044876992702484\n",
            "Epoch(0/1 : Batch number(559/782) : Batch loss : 0.5319490432739258\n",
            "Epoch(0/1 : Batch number(560/782) : Batch loss : 0.6977605819702148\n",
            "Epoch(0/1 : Batch number(561/782) : Batch loss : 0.5172936916351318\n",
            "Epoch(0/1 : Batch number(562/782) : Batch loss : 0.6899081468582153\n",
            "Epoch(0/1 : Batch number(563/782) : Batch loss : 0.574398398399353\n",
            "Epoch(0/1 : Batch number(564/782) : Batch loss : 0.7058438062667847\n",
            "Epoch(0/1 : Batch number(565/782) : Batch loss : 0.7470785975456238\n",
            "Epoch(0/1 : Batch number(566/782) : Batch loss : 0.5709460973739624\n",
            "Epoch(0/1 : Batch number(567/782) : Batch loss : 0.566903293132782\n",
            "Epoch(0/1 : Batch number(568/782) : Batch loss : 0.7473457455635071\n",
            "Epoch(0/1 : Batch number(569/782) : Batch loss : 0.4291061460971832\n",
            "Epoch(0/1 : Batch number(570/782) : Batch loss : 0.5712698101997375\n",
            "Epoch(0/1 : Batch number(571/782) : Batch loss : 0.6872696876525879\n",
            "Epoch(0/1 : Batch number(572/782) : Batch loss : 0.5872067809104919\n",
            "Epoch(0/1 : Batch number(573/782) : Batch loss : 0.7541184425354004\n",
            "Epoch(0/1 : Batch number(574/782) : Batch loss : 0.7653588056564331\n",
            "Epoch(0/1 : Batch number(575/782) : Batch loss : 0.9096017479896545\n",
            "Epoch(0/1 : Batch number(576/782) : Batch loss : 0.6931081414222717\n",
            "Epoch(0/1 : Batch number(577/782) : Batch loss : 0.6168285012245178\n",
            "Epoch(0/1 : Batch number(578/782) : Batch loss : 0.8455847501754761\n",
            "Epoch(0/1 : Batch number(579/782) : Batch loss : 0.6807063221931458\n",
            "Epoch(0/1 : Batch number(580/782) : Batch loss : 0.4445137679576874\n",
            "Epoch(0/1 : Batch number(581/782) : Batch loss : 0.8305322527885437\n",
            "Epoch(0/1 : Batch number(582/782) : Batch loss : 0.5595123171806335\n",
            "Epoch(0/1 : Batch number(583/782) : Batch loss : 0.8717322945594788\n",
            "Epoch(0/1 : Batch number(584/782) : Batch loss : 0.7675511837005615\n",
            "Epoch(0/1 : Batch number(585/782) : Batch loss : 0.7374598979949951\n",
            "Epoch(0/1 : Batch number(586/782) : Batch loss : 0.7368595004081726\n",
            "Epoch(0/1 : Batch number(587/782) : Batch loss : 0.5435298085212708\n",
            "Epoch(0/1 : Batch number(588/782) : Batch loss : 0.4796304404735565\n",
            "Epoch(0/1 : Batch number(589/782) : Batch loss : 0.7011184096336365\n",
            "Epoch(0/1 : Batch number(590/782) : Batch loss : 0.6815032362937927\n",
            "Epoch(0/1 : Batch number(591/782) : Batch loss : 0.6004502177238464\n",
            "Epoch(0/1 : Batch number(592/782) : Batch loss : 0.5611407160758972\n",
            "Epoch(0/1 : Batch number(593/782) : Batch loss : 0.5644620656967163\n",
            "Epoch(0/1 : Batch number(594/782) : Batch loss : 0.6559492349624634\n",
            "Epoch(0/1 : Batch number(595/782) : Batch loss : 0.5802808403968811\n",
            "Epoch(0/1 : Batch number(596/782) : Batch loss : 0.6756882071495056\n",
            "Epoch(0/1 : Batch number(597/782) : Batch loss : 0.595582127571106\n",
            "Epoch(0/1 : Batch number(598/782) : Batch loss : 0.7232351899147034\n",
            "Epoch(0/1 : Batch number(599/782) : Batch loss : 0.6914153695106506\n",
            "Epoch(0/1 : Batch number(600/782) : Batch loss : 0.6512588858604431\n",
            "Epoch(0/1 : Batch number(601/782) : Batch loss : 0.6706933975219727\n",
            "Epoch(0/1 : Batch number(602/782) : Batch loss : 0.8581392765045166\n",
            "Epoch(0/1 : Batch number(603/782) : Batch loss : 0.5456426739692688\n",
            "Epoch(0/1 : Batch number(604/782) : Batch loss : 0.6136485934257507\n",
            "Epoch(0/1 : Batch number(605/782) : Batch loss : 0.4198249578475952\n",
            "Epoch(0/1 : Batch number(606/782) : Batch loss : 0.6115313172340393\n",
            "Epoch(0/1 : Batch number(607/782) : Batch loss : 0.7643109560012817\n",
            "Epoch(0/1 : Batch number(608/782) : Batch loss : 0.5804485082626343\n",
            "Epoch(0/1 : Batch number(609/782) : Batch loss : 0.6828614473342896\n",
            "Epoch(0/1 : Batch number(610/782) : Batch loss : 0.8136574029922485\n",
            "Epoch(0/1 : Batch number(611/782) : Batch loss : 0.6836291551589966\n",
            "Epoch(0/1 : Batch number(612/782) : Batch loss : 0.5482197999954224\n",
            "Epoch(0/1 : Batch number(613/782) : Batch loss : 0.7376357913017273\n",
            "Epoch(0/1 : Batch number(614/782) : Batch loss : 0.5297467708587646\n",
            "Epoch(0/1 : Batch number(615/782) : Batch loss : 0.5981183052062988\n",
            "Epoch(0/1 : Batch number(616/782) : Batch loss : 0.6177310943603516\n",
            "Epoch(0/1 : Batch number(617/782) : Batch loss : 1.011286735534668\n",
            "Epoch(0/1 : Batch number(618/782) : Batch loss : 0.44242849946022034\n",
            "Epoch(0/1 : Batch number(619/782) : Batch loss : 0.5628624558448792\n",
            "Epoch(0/1 : Batch number(620/782) : Batch loss : 0.4142816364765167\n",
            "Epoch(0/1 : Batch number(621/782) : Batch loss : 0.7088874578475952\n",
            "Epoch(0/1 : Batch number(622/782) : Batch loss : 0.5502339601516724\n",
            "Epoch(0/1 : Batch number(623/782) : Batch loss : 0.5039697885513306\n",
            "Epoch(0/1 : Batch number(624/782) : Batch loss : 0.8602429032325745\n",
            "Epoch(0/1 : Batch number(625/782) : Batch loss : 0.629439115524292\n",
            "Epoch(0/1 : Batch number(626/782) : Batch loss : 0.8192957043647766\n",
            "Epoch(0/1 : Batch number(627/782) : Batch loss : 0.548324704170227\n",
            "Epoch(0/1 : Batch number(628/782) : Batch loss : 0.8660359382629395\n",
            "Epoch(0/1 : Batch number(629/782) : Batch loss : 0.7480655312538147\n",
            "Epoch(0/1 : Batch number(630/782) : Batch loss : 0.41646987199783325\n",
            "Epoch(0/1 : Batch number(631/782) : Batch loss : 0.6079047322273254\n",
            "Epoch(0/1 : Batch number(632/782) : Batch loss : 0.47067368030548096\n",
            "Epoch(0/1 : Batch number(633/782) : Batch loss : 0.6385207176208496\n",
            "Epoch(0/1 : Batch number(634/782) : Batch loss : 0.39863792061805725\n",
            "Epoch(0/1 : Batch number(635/782) : Batch loss : 0.8112825155258179\n",
            "Epoch(0/1 : Batch number(636/782) : Batch loss : 0.6936420202255249\n",
            "Epoch(0/1 : Batch number(637/782) : Batch loss : 0.5263750553131104\n",
            "Epoch(0/1 : Batch number(638/782) : Batch loss : 0.5519716143608093\n",
            "Epoch(0/1 : Batch number(639/782) : Batch loss : 0.4953495264053345\n",
            "Epoch(0/1 : Batch number(640/782) : Batch loss : 0.5622289180755615\n",
            "Epoch(0/1 : Batch number(641/782) : Batch loss : 0.754523515701294\n",
            "Epoch(0/1 : Batch number(642/782) : Batch loss : 0.7048630714416504\n",
            "Epoch(0/1 : Batch number(643/782) : Batch loss : 0.6317333579063416\n",
            "Epoch(0/1 : Batch number(644/782) : Batch loss : 0.5953419208526611\n",
            "Epoch(0/1 : Batch number(645/782) : Batch loss : 0.5578030347824097\n",
            "Epoch(0/1 : Batch number(646/782) : Batch loss : 0.6254776120185852\n",
            "Epoch(0/1 : Batch number(647/782) : Batch loss : 0.7079262137413025\n",
            "Epoch(0/1 : Batch number(648/782) : Batch loss : 0.8205583691596985\n",
            "Epoch(0/1 : Batch number(649/782) : Batch loss : 0.9124287962913513\n",
            "Epoch(0/1 : Batch number(650/782) : Batch loss : 1.0247445106506348\n",
            "Epoch(0/1 : Batch number(651/782) : Batch loss : 0.6228264570236206\n",
            "Epoch(0/1 : Batch number(652/782) : Batch loss : 0.7111532688140869\n",
            "Epoch(0/1 : Batch number(653/782) : Batch loss : 0.8397436141967773\n",
            "Epoch(0/1 : Batch number(654/782) : Batch loss : 0.6622304320335388\n",
            "Epoch(0/1 : Batch number(655/782) : Batch loss : 0.5717134475708008\n",
            "Epoch(0/1 : Batch number(656/782) : Batch loss : 0.5291945338249207\n",
            "Epoch(0/1 : Batch number(657/782) : Batch loss : 0.5931837558746338\n",
            "Epoch(0/1 : Batch number(658/782) : Batch loss : 0.6279277205467224\n",
            "Epoch(0/1 : Batch number(659/782) : Batch loss : 0.6521903872489929\n",
            "Epoch(0/1 : Batch number(660/782) : Batch loss : 0.8148940801620483\n",
            "Epoch(0/1 : Batch number(661/782) : Batch loss : 0.5266579389572144\n",
            "Epoch(0/1 : Batch number(662/782) : Batch loss : 0.9084711074829102\n",
            "Epoch(0/1 : Batch number(663/782) : Batch loss : 0.6907874941825867\n",
            "Epoch(0/1 : Batch number(664/782) : Batch loss : 0.6826828718185425\n",
            "Epoch(0/1 : Batch number(665/782) : Batch loss : 0.5550422072410583\n",
            "Epoch(0/1 : Batch number(666/782) : Batch loss : 0.3769073486328125\n",
            "Epoch(0/1 : Batch number(667/782) : Batch loss : 0.5648309588432312\n",
            "Epoch(0/1 : Batch number(668/782) : Batch loss : 0.6003086566925049\n",
            "Epoch(0/1 : Batch number(669/782) : Batch loss : 0.5160961151123047\n",
            "Epoch(0/1 : Batch number(670/782) : Batch loss : 0.5103049874305725\n",
            "Epoch(0/1 : Batch number(671/782) : Batch loss : 0.8552722334861755\n",
            "Epoch(0/1 : Batch number(672/782) : Batch loss : 0.8116061687469482\n",
            "Epoch(0/1 : Batch number(673/782) : Batch loss : 0.7223212718963623\n",
            "Epoch(0/1 : Batch number(674/782) : Batch loss : 0.642677366733551\n",
            "Epoch(0/1 : Batch number(675/782) : Batch loss : 0.641042947769165\n",
            "Epoch(0/1 : Batch number(676/782) : Batch loss : 0.45261046290397644\n",
            "Epoch(0/1 : Batch number(677/782) : Batch loss : 0.5890064835548401\n",
            "Epoch(0/1 : Batch number(678/782) : Batch loss : 0.7929956912994385\n",
            "Epoch(0/1 : Batch number(679/782) : Batch loss : 0.56987464427948\n",
            "Epoch(0/1 : Batch number(680/782) : Batch loss : 0.6660997867584229\n",
            "Epoch(0/1 : Batch number(681/782) : Batch loss : 0.6733077764511108\n",
            "Epoch(0/1 : Batch number(682/782) : Batch loss : 0.5418547987937927\n",
            "Epoch(0/1 : Batch number(683/782) : Batch loss : 0.6324002146720886\n",
            "Epoch(0/1 : Batch number(684/782) : Batch loss : 0.49503177404403687\n",
            "Epoch(0/1 : Batch number(685/782) : Batch loss : 0.7566354870796204\n",
            "Epoch(0/1 : Batch number(686/782) : Batch loss : 0.7883599996566772\n",
            "Epoch(0/1 : Batch number(687/782) : Batch loss : 0.38565951585769653\n",
            "Epoch(0/1 : Batch number(688/782) : Batch loss : 0.7183249592781067\n",
            "Epoch(0/1 : Batch number(689/782) : Batch loss : 0.6253045201301575\n",
            "Epoch(0/1 : Batch number(690/782) : Batch loss : 0.45585188269615173\n",
            "Epoch(0/1 : Batch number(691/782) : Batch loss : 0.6994523406028748\n",
            "Epoch(0/1 : Batch number(692/782) : Batch loss : 0.6072022318840027\n",
            "Epoch(0/1 : Batch number(693/782) : Batch loss : 0.7768484354019165\n",
            "Epoch(0/1 : Batch number(694/782) : Batch loss : 0.6398777365684509\n",
            "Epoch(0/1 : Batch number(695/782) : Batch loss : 0.8070000410079956\n",
            "Epoch(0/1 : Batch number(696/782) : Batch loss : 0.6847535967826843\n",
            "Epoch(0/1 : Batch number(697/782) : Batch loss : 0.6437310576438904\n",
            "Epoch(0/1 : Batch number(698/782) : Batch loss : 0.8037250638008118\n",
            "Epoch(0/1 : Batch number(699/782) : Batch loss : 0.7328705787658691\n",
            "Epoch(0/1 : Batch number(700/782) : Batch loss : 0.5311241149902344\n",
            "Epoch(0/1 : Batch number(701/782) : Batch loss : 0.5093950033187866\n",
            "Epoch(0/1 : Batch number(702/782) : Batch loss : 0.6241416335105896\n",
            "Epoch(0/1 : Batch number(703/782) : Batch loss : 0.5924779772758484\n",
            "Epoch(0/1 : Batch number(704/782) : Batch loss : 0.8057150840759277\n",
            "Epoch(0/1 : Batch number(705/782) : Batch loss : 0.5009971857070923\n",
            "Epoch(0/1 : Batch number(706/782) : Batch loss : 0.630652666091919\n",
            "Epoch(0/1 : Batch number(707/782) : Batch loss : 0.7581929564476013\n",
            "Epoch(0/1 : Batch number(708/782) : Batch loss : 0.4595625102519989\n",
            "Epoch(0/1 : Batch number(709/782) : Batch loss : 0.8116437196731567\n",
            "Epoch(0/1 : Batch number(710/782) : Batch loss : 0.7452070116996765\n",
            "Epoch(0/1 : Batch number(711/782) : Batch loss : 0.6041880249977112\n",
            "Epoch(0/1 : Batch number(712/782) : Batch loss : 0.7934000492095947\n",
            "Epoch(0/1 : Batch number(713/782) : Batch loss : 0.630632221698761\n",
            "Epoch(0/1 : Batch number(714/782) : Batch loss : 0.8007172346115112\n",
            "Epoch(0/1 : Batch number(715/782) : Batch loss : 0.9772170782089233\n",
            "Epoch(0/1 : Batch number(716/782) : Batch loss : 0.4738544821739197\n",
            "Epoch(0/1 : Batch number(717/782) : Batch loss : 0.7057523131370544\n",
            "Epoch(0/1 : Batch number(718/782) : Batch loss : 0.7001733183860779\n",
            "Epoch(0/1 : Batch number(719/782) : Batch loss : 0.693541407585144\n",
            "Epoch(0/1 : Batch number(720/782) : Batch loss : 0.6957318186759949\n",
            "Epoch(0/1 : Batch number(721/782) : Batch loss : 0.8804012537002563\n",
            "Epoch(0/1 : Batch number(722/782) : Batch loss : 0.560333251953125\n",
            "Epoch(0/1 : Batch number(723/782) : Batch loss : 0.6187955737113953\n",
            "Epoch(0/1 : Batch number(724/782) : Batch loss : 0.4391542375087738\n",
            "Epoch(0/1 : Batch number(725/782) : Batch loss : 0.8750240206718445\n",
            "Epoch(0/1 : Batch number(726/782) : Batch loss : 0.5845909714698792\n",
            "Epoch(0/1 : Batch number(727/782) : Batch loss : 0.4228373169898987\n",
            "Epoch(0/1 : Batch number(728/782) : Batch loss : 0.848019003868103\n",
            "Epoch(0/1 : Batch number(729/782) : Batch loss : 0.5384352803230286\n",
            "Epoch(0/1 : Batch number(730/782) : Batch loss : 0.6342194676399231\n",
            "Epoch(0/1 : Batch number(731/782) : Batch loss : 0.5378395915031433\n",
            "Epoch(0/1 : Batch number(732/782) : Batch loss : 0.6938192248344421\n",
            "Epoch(0/1 : Batch number(733/782) : Batch loss : 0.7019831538200378\n",
            "Epoch(0/1 : Batch number(734/782) : Batch loss : 0.5804126262664795\n",
            "Epoch(0/1 : Batch number(735/782) : Batch loss : 0.46616268157958984\n",
            "Epoch(0/1 : Batch number(736/782) : Batch loss : 0.6756159663200378\n",
            "Epoch(0/1 : Batch number(737/782) : Batch loss : 0.503054678440094\n",
            "Epoch(0/1 : Batch number(738/782) : Batch loss : 0.8192870616912842\n",
            "Epoch(0/1 : Batch number(739/782) : Batch loss : 0.890388548374176\n",
            "Epoch(0/1 : Batch number(740/782) : Batch loss : 0.7500022053718567\n",
            "Epoch(0/1 : Batch number(741/782) : Batch loss : 0.7825025320053101\n",
            "Epoch(0/1 : Batch number(742/782) : Batch loss : 0.5652205944061279\n",
            "Epoch(0/1 : Batch number(743/782) : Batch loss : 0.6027003526687622\n",
            "Epoch(0/1 : Batch number(744/782) : Batch loss : 0.6382362842559814\n",
            "Epoch(0/1 : Batch number(745/782) : Batch loss : 0.8327123522758484\n",
            "Epoch(0/1 : Batch number(746/782) : Batch loss : 0.8380255699157715\n",
            "Epoch(0/1 : Batch number(747/782) : Batch loss : 0.44243770837783813\n",
            "Epoch(0/1 : Batch number(748/782) : Batch loss : 0.5409255623817444\n",
            "Epoch(0/1 : Batch number(749/782) : Batch loss : 0.7673868536949158\n",
            "Epoch(0/1 : Batch number(750/782) : Batch loss : 0.8121789693832397\n",
            "Epoch(0/1 : Batch number(751/782) : Batch loss : 0.837012767791748\n",
            "Epoch(0/1 : Batch number(752/782) : Batch loss : 0.4310937523841858\n",
            "Epoch(0/1 : Batch number(753/782) : Batch loss : 0.6706624031066895\n",
            "Epoch(0/1 : Batch number(754/782) : Batch loss : 0.5401715636253357\n",
            "Epoch(0/1 : Batch number(755/782) : Batch loss : 0.6612712740898132\n",
            "Epoch(0/1 : Batch number(756/782) : Batch loss : 0.8384940028190613\n",
            "Epoch(0/1 : Batch number(757/782) : Batch loss : 0.5194501280784607\n",
            "Epoch(0/1 : Batch number(758/782) : Batch loss : 0.5088633298873901\n",
            "Epoch(0/1 : Batch number(759/782) : Batch loss : 0.5121363401412964\n",
            "Epoch(0/1 : Batch number(760/782) : Batch loss : 0.6801913976669312\n",
            "Epoch(0/1 : Batch number(761/782) : Batch loss : 0.5822051763534546\n",
            "Epoch(0/1 : Batch number(762/782) : Batch loss : 0.5350553393363953\n",
            "Epoch(0/1 : Batch number(763/782) : Batch loss : 0.7051180601119995\n",
            "Epoch(0/1 : Batch number(764/782) : Batch loss : 0.6717475652694702\n",
            "Epoch(0/1 : Batch number(765/782) : Batch loss : 0.6492129564285278\n",
            "Epoch(0/1 : Batch number(766/782) : Batch loss : 0.8866169452667236\n",
            "Epoch(0/1 : Batch number(767/782) : Batch loss : 0.6060456037521362\n",
            "Epoch(0/1 : Batch number(768/782) : Batch loss : 0.6203145384788513\n",
            "Epoch(0/1 : Batch number(769/782) : Batch loss : 0.5798656344413757\n",
            "Epoch(0/1 : Batch number(770/782) : Batch loss : 0.46809110045433044\n",
            "Epoch(0/1 : Batch number(771/782) : Batch loss : 0.8039828538894653\n",
            "Epoch(0/1 : Batch number(772/782) : Batch loss : 0.43692895770072937\n",
            "Epoch(0/1 : Batch number(773/782) : Batch loss : 0.5076591372489929\n",
            "Epoch(0/1 : Batch number(774/782) : Batch loss : 0.6554039120674133\n",
            "Epoch(0/1 : Batch number(775/782) : Batch loss : 0.5029258131980896\n",
            "Epoch(0/1 : Batch number(776/782) : Batch loss : 0.3458063304424286\n",
            "Epoch(0/1 : Batch number(777/782) : Batch loss : 0.5649893283843994\n",
            "Epoch(0/1 : Batch number(778/782) : Batch loss : 0.6083918809890747\n",
            "Epoch(0/1 : Batch number(779/782) : Batch loss : 0.8221242427825928\n",
            "Epoch(0/1 : Batch number(780/782) : Batch loss : 0.6604328751564026\n",
            "Epoch(0/1 : Batch number(781/782) : Batch loss : 0.5783718824386597\n",
            "Epoch(0/1 : Batch number(782/782) : Batch loss : 0.9337775707244873\n",
            "Training loss : 0.7058981776313709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6j6rXQe_ZfW"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPEeLaHK_ZfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9e53c0-ed00-4204-856e-42c7ec9d9b13"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch (1/157)\n",
            "Batch (2/157)\n",
            "Batch (3/157)\n",
            "Batch (4/157)\n",
            "Batch (5/157)\n",
            "Accuracy of the model on 320 test images: 82.5% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLAXsh1S5XB9"
      },
      "source": [
        "## Un-freezing & training on the LAST CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7nvP9B9R8b"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaUeud5I7Tez"
      },
      "source": [
        "for i in range(24,31):\n",
        "  model.features[i].requires_grad = True\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_-YlZp5XB-"
      },
      "source": [
        "model = model.to(device)\n",
        "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 3\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2dNQIjt9JQo"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ichHhboE9JQp"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbOYwAC9rVq"
      },
      "source": [
        "## Un-freezing & training on the LAST TWO CNN block onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teTUgZSz9rVt"
      },
      "source": [
        "### Re-training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkn85do59rVw"
      },
      "source": [
        "for i in range(17,24):\n",
        "  model.features[i].requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuEGcaqalvuU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrzemsJ9rV1"
      },
      "source": [
        "model = model.to(device)\n",
        "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "num_epochs = 1\n",
        "batch_loss = 0\n",
        "cum_epoch_loss = 0\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  cum_epoch_loss = 0\n",
        "  \n",
        "  for batch, (images, labels) in enumerate(trainloader,1):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    batch_loss += loss.item()\n",
        "    print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)}) : Batch loss : {loss.item()}')\n",
        "    \n",
        "  print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md_RCnNg9rV7"
      },
      "source": [
        "### The accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoeCTt29rV8"
      },
      "source": [
        "model.to('cpu')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "        print(f'Batch ({batch}/{len(testloader)})')\n",
        "        \n",
        "        if batch == 5:\n",
        "          break\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}